{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vSycRc_AwcW9",
        "outputId": "f5aa3faa-d463-443a-fae0-949f1503e2bf"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting docling\n",
            "  Downloading docling-2.32.0-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting beautifulsoup4<5.0.0,>=4.12.3 (from docling)\n",
            "  Downloading beautifulsoup4-4.13.4-py3-none-any.whl.metadata (3.8 kB)\n",
            "Requirement already satisfied: certifi>=2024.7.4 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (2025.4.26)\n",
            "Requirement already satisfied: click<8.2.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (8.1.8)\n",
            "Requirement already satisfied: docling-core<3.0.0,>=2.26.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-core[chunking]<3.0.0,>=2.26.0->docling) (2.30.1)\n",
            "Collecting docling-ibm-models<4.0.0,>=3.4.0 (from docling)\n",
            "  Downloading docling_ibm_models-3.4.3-py3-none-any.whl.metadata (7.6 kB)\n",
            "Collecting docling-parse<5.0.0,>=4.0.0 (from docling)\n",
            "  Downloading docling_parse-4.0.1-cp311-cp311-macosx_14_0_arm64.whl.metadata (9.6 kB)\n",
            "Collecting easyocr<2.0,>=1.7 (from docling)\n",
            "  Downloading easyocr-1.7.2-py3-none-any.whl.metadata (10 kB)\n",
            "Collecting filetype<2.0.0,>=1.2.0 (from docling)\n",
            "  Downloading filetype-1.2.0-py2.py3-none-any.whl.metadata (6.5 kB)\n",
            "Requirement already satisfied: huggingface_hub<1,>=0.23 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (0.31.2)\n",
            "Collecting lxml<6.0.0,>=4.0.0 (from docling)\n",
            "  Downloading lxml-5.4.0-cp311-cp311-macosx_10_9_universal2.whl.metadata (3.5 kB)\n",
            "Collecting marko<3.0.0,>=2.1.2 (from docling)\n",
            "  Downloading marko-2.1.3-py3-none-any.whl.metadata (4.5 kB)\n",
            "Collecting openpyxl<4.0.0,>=3.1.5 (from docling)\n",
            "  Downloading openpyxl-3.1.5-py2.py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: pandas<3.0.0,>=2.1.4 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (2.2.3)\n",
            "Requirement already satisfied: pillow<12.0.0,>=10.0.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (11.2.1)\n",
            "Collecting pluggy<2.0.0,>=1.0.0 (from docling)\n",
            "  Downloading pluggy-1.6.0-py3-none-any.whl.metadata (4.8 kB)\n",
            "Requirement already satisfied: pydantic<3.0.0,>=2.0.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (2.11.4)\n",
            "Collecting pydantic-settings<3.0.0,>=2.3.0 (from docling)\n",
            "  Downloading pydantic_settings-2.9.1-py3-none-any.whl.metadata (3.8 kB)\n",
            "Collecting pylatexenc<3.0,>=2.10 (from docling)\n",
            "  Downloading pylatexenc-2.10.tar.gz (162 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m162.6/162.6 kB\u001b[0m \u001b[31m3.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25h  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: pypdfium2<5.0.0,>=4.30.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (4.30.1)\n",
            "Collecting python-docx<2.0.0,>=1.1.2 (from docling)\n",
            "  Downloading python_docx-1.1.2-py3-none-any.whl.metadata (2.0 kB)\n",
            "Collecting python-pptx<2.0.0,>=1.0.2 (from docling)\n",
            "  Downloading python_pptx-1.0.2-py3-none-any.whl.metadata (2.5 kB)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.32.2 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (2.32.3)\n",
            "Collecting rtree<2.0.0,>=1.3.0 (from docling)\n",
            "  Downloading rtree-1.4.0-py3-none-macosx_11_0_arm64.whl.metadata (2.1 kB)\n",
            "Requirement already satisfied: scipy<2.0.0,>=1.6.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (1.15.3)\n",
            "Requirement already satisfied: tqdm<5.0.0,>=4.65.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (4.67.1)\n",
            "Requirement already satisfied: typer<0.16.0,>=0.12.5 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling) (0.15.4)\n",
            "Collecting soupsieve>1.2 (from beautifulsoup4<5.0.0,>=4.12.3->docling)\n",
            "  Downloading soupsieve-2.7-py3-none-any.whl.metadata (4.6 kB)\n",
            "Requirement already satisfied: typing-extensions>=4.0.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from beautifulsoup4<5.0.0,>=4.12.3->docling) (4.13.2)\n",
            "Requirement already satisfied: jsonref<2.0.0,>=1.1.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (1.1.0)\n",
            "Requirement already satisfied: jsonschema<5.0.0,>=4.16.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (4.23.0)\n",
            "Requirement already satisfied: latex2mathml<4.0.0,>=3.77.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (3.78.0)\n",
            "Requirement already satisfied: pyyaml<7.0.0,>=5.1 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (6.0.2)\n",
            "Requirement already satisfied: tabulate<0.10.0,>=0.9.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.9.0)\n",
            "Collecting semchunk<3.0.0,>=2.2.0 (from docling-core[chunking]<3.0.0,>=2.26.0->docling)\n",
            "  Downloading semchunk-2.2.2-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: transformers<5.0.0,>=4.34.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-core[chunking]<3.0.0,>=2.26.0->docling) (4.51.3)\n",
            "Collecting jsonlines<4.0.0,>=3.1.0 (from docling-ibm-models<4.0.0,>=3.4.0->docling)\n",
            "  Downloading jsonlines-3.1.0-py3-none-any.whl.metadata (1.7 kB)\n",
            "Requirement already satisfied: numpy<3.0.0,>=1.24.4 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (2.2.5)\n",
            "Collecting opencv-python-headless<5.0.0.0,>=4.6.0.66 (from docling-ibm-models<4.0.0,>=3.4.0->docling)\n",
            "  Downloading opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl.metadata (20 kB)\n",
            "Requirement already satisfied: safetensors<1,>=0.4.3 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from safetensors[torch]<1,>=0.4.3->docling-ibm-models<4.0.0,>=3.4.0->docling) (0.5.3)\n",
            "Requirement already satisfied: torch<3.0.0,>=2.2.2 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (2.7.0)\n",
            "Requirement already satisfied: torchvision<1,>=0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from docling-ibm-models<4.0.0,>=3.4.0->docling) (0.22.0)\n",
            "Collecting scikit-image (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading scikit_image-0.25.2-cp311-cp311-macosx_12_0_arm64.whl.metadata (14 kB)\n",
            "Collecting python-bidi (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading python_bidi-0.6.6-cp311-cp311-macosx_11_0_arm64.whl.metadata (4.9 kB)\n",
            "Collecting Shapely (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading shapely-2.1.1-cp311-cp311-macosx_11_0_arm64.whl.metadata (6.8 kB)\n",
            "Collecting pyclipper (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading pyclipper-1.3.0.post6-cp311-cp311-macosx_10_9_universal2.whl.metadata (9.0 kB)\n",
            "Collecting ninja (from easyocr<2.0,>=1.7->docling)\n",
            "  Downloading ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl.metadata (5.0 kB)\n",
            "Requirement already satisfied: filelock in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from huggingface_hub<1,>=0.23->docling) (3.18.0)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from huggingface_hub<1,>=0.23->docling) (2025.3.0)\n",
            "Requirement already satisfied: packaging>=20.9 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from huggingface_hub<1,>=0.23->docling) (25.0)\n",
            "Collecting et-xmlfile (from openpyxl<4.0.0,>=3.1.5->docling)\n",
            "  Downloading et_xmlfile-2.0.0-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pandas<3.0.0,>=2.1.4->docling) (2025.2)\n",
            "Requirement already satisfied: annotated-types>=0.6.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.7.0)\n",
            "Requirement already satisfied: pydantic-core==2.33.2 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->docling) (2.33.2)\n",
            "Requirement already satisfied: typing-inspection>=0.4.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pydantic<3.0.0,>=2.0.0->docling) (0.4.0)\n",
            "Collecting python-dotenv>=0.21.0 (from pydantic-settings<3.0.0,>=2.3.0->docling)\n",
            "  Downloading python_dotenv-1.1.0-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting XlsxWriter>=0.5.7 (from python-pptx<2.0.0,>=1.0.2->docling)\n",
            "  Downloading XlsxWriter-3.2.3-py3-none-any.whl.metadata (2.7 kB)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.2->docling) (3.4.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.2->docling) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from requests<3.0.0,>=2.32.2->docling) (2.4.0)\n",
            "Requirement already satisfied: shellingham>=1.3.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from typer<0.16.0,>=0.12.5->docling) (1.5.4)\n",
            "Requirement already satisfied: rich>=10.11.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from typer<0.16.0,>=0.12.5->docling) (14.0.0)\n",
            "Requirement already satisfied: attrs>=19.2.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from jsonlines<4.0.0,>=3.1.0->docling-ibm-models<4.0.0,>=3.4.0->docling) (25.3.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (2025.4.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.36.2)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from jsonschema<5.0.0,>=4.16.0->docling-core<3.0.0,>=2.26.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.25.0)\n",
            "Requirement already satisfied: six>=1.5 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas<3.0.0,>=2.1.4->docling) (1.17.0)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (2.19.1)\n",
            "Collecting mpire[dill] (from semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.26.0->docling)\n",
            "  Downloading mpire-2.10.2-py3-none-any.whl.metadata (14 kB)\n",
            "Requirement already satisfied: sympy>=1.13.3 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (1.14.0)\n",
            "Requirement already satisfied: networkx in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.1.6)\n",
            "Requirement already satisfied: regex!=2019.12.17 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (2024.11.6)\n",
            "Requirement already satisfied: tokenizers<0.22,>=0.21 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from transformers<5.0.0,>=4.34.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.21.1)\n",
            "Collecting imageio!=2.35.0,>=2.33 (from scikit-image->easyocr<2.0,>=1.7->docling)\n",
            "  Downloading imageio-2.37.0-py3-none-any.whl.metadata (5.2 kB)\n",
            "Collecting tifffile>=2022.8.12 (from scikit-image->easyocr<2.0,>=1.7->docling)\n",
            "  Downloading tifffile-2025.5.10-py3-none-any.whl.metadata (31 kB)\n",
            "Collecting lazy-loader>=0.4 (from scikit-image->easyocr<2.0,>=1.7->docling)\n",
            "  Downloading lazy_loader-0.4-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: mdurl~=0.1 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from markdown-it-py>=2.2.0->rich>=10.11.0->typer<0.16.0,>=0.12.5->docling) (0.1.2)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from sympy>=1.13.3->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from jinja2->torch<3.0.0,>=2.2.2->docling-ibm-models<4.0.0,>=3.4.0->docling) (3.0.2)\n",
            "Requirement already satisfied: multiprocess>=0.70.15 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.70.16)\n",
            "Requirement already satisfied: dill>=0.3.8 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from multiprocess>=0.70.15->mpire[dill]->semchunk<3.0.0,>=2.2.0->docling-core[chunking]<3.0.0,>=2.26.0->docling) (0.3.8)\n",
            "Downloading docling-2.32.0-py3-none-any.whl (166 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m166.7/166.7 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading beautifulsoup4-4.13.4-py3-none-any.whl (187 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m187.3/187.3 kB\u001b[0m \u001b[31m402.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading docling_ibm_models-3.4.3-py3-none-any.whl (80 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m80.9/80.9 kB\u001b[0m \u001b[31m374.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading docling_parse-4.0.1-cp311-cp311-macosx_14_0_arm64.whl (14.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m14.6/14.6 MB\u001b[0m \u001b[31m344.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading easyocr-1.7.2-py3-none-any.whl (2.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.9/2.9 MB\u001b[0m \u001b[31m348.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading filetype-1.2.0-py2.py3-none-any.whl (19 kB)\n",
            "Downloading lxml-5.4.0-cp311-cp311-macosx_10_9_universal2.whl (8.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m346.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading marko-2.1.3-py3-none-any.whl (42 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m42.2/42.2 kB\u001b[0m \u001b[31m291.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading openpyxl-3.1.5-py2.py3-none-any.whl (250 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m250.9/250.9 kB\u001b[0m \u001b[31m370.1 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pluggy-1.6.0-py3-none-any.whl (20 kB)\n",
            "Downloading pydantic_settings-2.9.1-py3-none-any.whl (44 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m44.4/44.4 kB\u001b[0m \u001b[31m683.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading python_docx-1.1.2-py3-none-any.whl (244 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m244.3/244.3 kB\u001b[0m \u001b[31m341.6 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading python_pptx-1.0.2-py3-none-any.whl (472 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m472.8/472.8 kB\u001b[0m \u001b[31m361.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading rtree-1.4.0-py3-none-macosx_11_0_arm64.whl (439 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m439.8/439.8 kB\u001b[0m \u001b[31m372.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading jsonlines-3.1.0-py3-none-any.whl (8.6 kB)\n",
            "Downloading opencv_python_headless-4.11.0.86-cp37-abi3-macosx_13_0_arm64.whl (37.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m37.3/37.3 MB\u001b[0m \u001b[31m341.3 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:03\u001b[0m\n",
            "\u001b[?25hDownloading python_dotenv-1.1.0-py3-none-any.whl (20 kB)\n",
            "Downloading semchunk-2.2.2-py3-none-any.whl (10 kB)\n",
            "Downloading soupsieve-2.7-py3-none-any.whl (36 kB)\n",
            "Downloading XlsxWriter-3.2.3-py3-none-any.whl (169 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m169.4/169.4 kB\u001b[0m \u001b[31m511.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading et_xmlfile-2.0.0-py3-none-any.whl (18 kB)\n",
            "Downloading ninja-1.11.1.4-py3-none-macosx_10_9_universal2.whl (279 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m279.1/279.1 kB\u001b[0m \u001b[31m390.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading pyclipper-1.3.0.post6-cp311-cp311-macosx_10_9_universal2.whl (270 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m270.9/270.9 kB\u001b[0m \u001b[31m352.2 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading python_bidi-0.6.6-cp311-cp311-macosx_11_0_arm64.whl (264 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m264.0/264.0 kB\u001b[0m \u001b[31m362.5 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading scikit_image-0.25.2-cp311-cp311-macosx_12_0_arm64.whl (13.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.2/13.2 MB\u001b[0m \u001b[31m329.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:02\u001b[0m\n",
            "\u001b[?25hDownloading shapely-2.1.1-cp311-cp311-macosx_11_0_arm64.whl (1.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.6/1.6 MB\u001b[0m \u001b[31m345.7 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading imageio-2.37.0-py3-none-any.whl (315 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m315.8/315.8 kB\u001b[0m \u001b[31m358.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0ma \u001b[36m0:00:01\u001b[0m\n",
            "\u001b[?25hDownloading lazy_loader-0.4-py3-none-any.whl (12 kB)\n",
            "Downloading tifffile-2025.5.10-py3-none-any.whl (226 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m226.5/226.5 kB\u001b[0m \u001b[31m369.4 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading mpire-2.10.2-py3-none-any.whl (272 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m272.8/272.8 kB\u001b[0m \u001b[31m333.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: pylatexenc\n",
            "  Building wheel for pylatexenc (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for pylatexenc: filename=pylatexenc-2.10-py3-none-any.whl size=136896 sha256=9dde003dd333ab07387d8e18c6e7e45126e1352b85166e290f966fb92a8a3de2\n",
            "  Stored in directory: /Users/cesarlarragueta/Library/Caches/pip/wheels/b1/7a/33/9fdd892f784ed4afda62b685ae3703adf4c91aa0f524c28f03\n",
            "Successfully built pylatexenc\n",
            "Installing collected packages: python-bidi, pylatexenc, pyclipper, filetype, XlsxWriter, tifffile, soupsieve, Shapely, rtree, python-dotenv, pluggy, opencv-python-headless, ninja, mpire, marko, lxml, lazy-loader, jsonlines, imageio, et-xmlfile, scikit-image, python-pptx, python-docx, openpyxl, beautifulsoup4, semchunk, pydantic-settings, easyocr, docling-parse, docling-ibm-models, docling\n",
            "Successfully installed Shapely-2.1.1 XlsxWriter-3.2.3 beautifulsoup4-4.13.4 docling-2.32.0 docling-ibm-models-3.4.3 docling-parse-4.0.1 easyocr-1.7.2 et-xmlfile-2.0.0 filetype-1.2.0 imageio-2.37.0 jsonlines-3.1.0 lazy-loader-0.4 lxml-5.4.0 marko-2.1.3 mpire-2.10.2 ninja-1.11.1.4 opencv-python-headless-4.11.0.86 openpyxl-3.1.5 pluggy-1.6.0 pyclipper-1.3.0.post6 pydantic-settings-2.9.1 pylatexenc-2.10 python-bidi-0.6.6 python-docx-1.1.2 python-dotenv-1.1.0 python-pptx-1.0.2 rtree-1.4.0 scikit-image-0.25.2 semchunk-2.2.2 soupsieve-2.7 tifffile-2025.5.10\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install docling\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BPUtp5oWwf0M",
        "outputId": "b831812a-b00f-4e7c-88df-c4e65573f165"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/huggingface_hub/utils/_auth.py:94: UserWarning: \n",
            "The secret `HF_TOKEN` does not exist in your Colab secrets.\n",
            "To authenticate with the Hugging Face Hub, create a token in your settings tab (https://huggingface.co/settings/tokens), set it as secret in your Google Colab and restart your session.\n",
            "You will be able to reuse this secret in all of your notebooks.\n",
            "Please note that authentication is recommended but still optional to access public models or datasets.\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "✅ Données extraites sauvegardées dans : invoice_data.json\n",
            "Résumé :\n",
            "- Numéro de facture : None\n",
            "- Date : None\n",
            "- Montant total : None\n",
            "- Nombre d'articles : 0\n"
          ]
        }
      ],
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "import re\n",
        "from google.colab import drive\n",
        "\n",
        "# Monter Google Drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "\n",
        "# Fonction pour extraire les données structurées depuis le JSON brut\n",
        "def extract_invoice_data(raw_json):\n",
        "    \"\"\"\n",
        "    Extrait les données clés d'une facture depuis un JSON non structuré.\n",
        "    Retourne un dictionnaire avec les champs : invoice_number, date, total_amount, client_name, line_items.\n",
        "    \"\"\"\n",
        "    extracted_data = {\n",
        "        \"invoice_number\": None,\n",
        "        \"date\": None,\n",
        "        \"total_amount\": None,\n",
        "        \"client_name\": None,\n",
        "        \"line_items\": []\n",
        "    }\n",
        "\n",
        "    # 1. Analyse du texte libre (ex: en-tête de facture)\n",
        "    if \"content\" in raw_json:\n",
        "        for item in raw_json[\"content\"]:\n",
        "            if item.get(\"type\") == \"text\":\n",
        "                text = item[\"value\"].strip().lower()\n",
        "\n",
        "                # Détection du numéro de facture (ex: \"Facture N°: INV-123\")\n",
        "                if \"facture n°\" in text or \"invoice no\" in text:\n",
        "                    extracted_data[\"invoice_number\"] = re.search(r\"(facture n°|invoice no)[:\\s]*([A-Z0-9-]+)\", text, re.IGNORECASE).group(2).strip()\n",
        "\n",
        "                # Détection de la date (ex: \"Date: 01/01/2023\")\n",
        "                if \"date\" in text and not extracted_data[\"date\"]:\n",
        "                    date_match = re.search(r\"(date|le)[:\\s]*([0-9]{2}/[0-9]{2}/[0-9]{4})\", text, re.IGNORECASE)\n",
        "                    if date_match:\n",
        "                        extracted_data[\"date\"] = date_match.group(2)\n",
        "\n",
        "                # Détection du client (ex: \"Client: John Doe\")\n",
        "                if \"client\" in text and not extracted_data[\"client_name\"]:\n",
        "                    client_match = re.search(r\"(client|customer)[:\\s]*(.+)\", text, re.IGNORECASE)\n",
        "                    if client_match:\n",
        "                        extracted_data[\"client_name\"] = client_match.group(2).strip()\n",
        "\n",
        "    # 2. Analyse des tables (ex: lignes de facture)\n",
        "    if \"tables\" in raw_json:\n",
        "        for table in raw_json[\"tables\"]:\n",
        "            for row in table.get(\"rows\", []):\n",
        "                # Détection du montant total (ex: \"Total HT: 100.00 €\")\n",
        "                if \"total\" in row[0].lower():\n",
        "                    extracted_data[\"total_amount\"] = float(re.sub(r\"[^\\d.]\", \"\", row[-1]))  # Supprime les symboles non numériques\n",
        "\n",
        "                # Détection des articles (ex: [\"1\", \"Produit A\", \"50.00\"])\n",
        "                if len(row) >= 3 and row[0].isdigit():\n",
        "                    extracted_data[\"line_items\"].append({\n",
        "                        \"quantity\": int(row[0]),\n",
        "                        \"description\": row[1],\n",
        "                        \"unit_price\": float(re.sub(r\"[^\\d.]\", \"\", row[2]))\n",
        "                    })\n",
        "\n",
        "    return extracted_data\n",
        "\n",
        "# ---------------------------------------------------------------\n",
        "# Exemple d'utilisation avec votre pipeline existant\n",
        "# ---------------------------------------------------------------\n",
        "from docling.document_converter import DocumentConverter\n",
        "\n",
        "# Étape 1: Conversion du PDF en JSON via docling\n",
        "source_pdf = \"/content/drive/MyDrive/nsia.pdf\"\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(source_pdf)\n",
        "raw_json = result.document.export_to_dict()  # JSON brut\n",
        "\n",
        "# Étape 2: Extraction des données ciblées\n",
        "cleaned_data = extract_invoice_data(raw_json)\n",
        "\n",
        "# Étape 3: Sauvegarde du résultat\n",
        "output_path = Path(\"invoice_data.json\")\n",
        "with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(cleaned_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(f\"✅ Données extraites sauvegardées dans : {output_path}\")\n",
        "print(\"Résumé :\")\n",
        "print(f\"- Numéro de facture : {cleaned_data.get('invoice_number')}\")\n",
        "print(f\"- Date : {cleaned_data.get('date')}\")\n",
        "print(f\"- Montant total : {cleaned_data.get('total_amount')}\")\n",
        "print(f\"- Nombre d'articles : {len(cleaned_data.get('line_items', []))}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "V6rUIu0D27KE",
        "outputId": "c791253c-9696-4785-93da-06eb3ffb446e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting tabula\n",
            "  Downloading tabula-1.0.5.tar.gz (9.5 kB)\n",
            "  Installing build dependencies ... \u001b[?25ldone\n",
            "\u001b[?25h  Getting requirements to build wheel ... \u001b[?25ldone\n",
            "\u001b[?25h  Preparing metadata (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25hRequirement already satisfied: setuptools in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from tabula) (65.5.0)\n",
            "Requirement already satisfied: numpy in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from tabula) (2.2.5)\n",
            "Building wheels for collected packages: tabula\n",
            "  Building wheel for tabula (pyproject.toml) ... \u001b[?25ldone\n",
            "\u001b[?25h  Created wheel for tabula: filename=tabula-1.0.5-py3-none-any.whl size=10676 sha256=08730e38b0045e70269691c0d4fbb74a4fd2c51510d678cd13adf9c1303c29fe\n",
            "  Stored in directory: /Users/cesarlarragueta/Library/Caches/pip/wheels/db/bb/71/f5d253c5eb10c8820dfd0590cd228e312b0768adc537466b45\n",
            "Successfully built tabula\n",
            "Installing collected packages: tabula\n",
            "Successfully installed tabula-1.0.5\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!pip install tabula\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JfZCtECJ4a_d",
        "outputId": "85c12ca6-0a6f-4ab5-ee8f-fadf21db62d8"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "/bin/bash: apt-get: command not found\n",
            "Collecting tabula-py\n",
            "  Downloading tabula_py-2.10.0-py3-none-any.whl.metadata (7.6 kB)\n",
            "Requirement already satisfied: pandas>=0.25.3 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from tabula-py) (2.2.3)\n",
            "Requirement already satisfied: numpy>1.24.4 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from tabula-py) (2.2.5)\n",
            "Collecting distro (from tabula-py)\n",
            "  Downloading distro-1.9.0-py3-none-any.whl.metadata (6.8 kB)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2.9.0.post0)\n",
            "Requirement already satisfied: pytz>=2020.1 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from pandas>=0.25.3->tabula-py) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /Users/cesarlarragueta/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages (from python-dateutil>=2.8.2->pandas>=0.25.3->tabula-py) (1.17.0)\n",
            "Downloading tabula_py-2.10.0-py3-none-any.whl (12.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m12.0/12.0 MB\u001b[0m \u001b[31m346.0 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m00:01\u001b[0m00:01\u001b[0m\n",
            "\u001b[?25hDownloading distro-1.9.0-py3-none-any.whl (20 kB)\n",
            "Installing collected packages: distro, tabula-py\n",
            "Successfully installed distro-1.9.0 tabula-py-2.10.0\n",
            "\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m A new release of pip is available: \u001b[0m\u001b[31;49m24.0\u001b[0m\u001b[39;49m -> \u001b[0m\u001b[32;49m25.1.1\u001b[0m\n",
            "\u001b[1m[\u001b[0m\u001b[34;49mnotice\u001b[0m\u001b[1;39;49m]\u001b[0m\u001b[39;49m To update, run: \u001b[0m\u001b[32;49mpip install --upgrade pip\u001b[0m\n"
          ]
        }
      ],
      "source": [
        "!apt-get install openjdk-11-jdk -y\n",
        "!pip install tabula-py\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "id": "qwYRVyBj4d5I"
      },
      "outputs": [],
      "source": [
        "import os\n",
        "os.environ[\"JAVA_HOME\"] = \"/usr/lib/jvm/java-11-openjdk-amd64\"\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3P750DSa2yck",
        "outputId": "4298c1df-fb1c-47de-ed91-13a4b88c1515"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Failed to import jpype dependencies. Fallback to subprocess.\n",
            "No module named 'jpype'\n",
            "Got stderr: mai 19, 2025 3:09:23 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider loadDiskCache\n",
            "AVERTISSEMENT: New fonts found, font cache will be re-built\n",
            "mai 19, 2025 3:09:23 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "AVERTISSEMENT: Building on-disk font cache, this may take a while\n",
            "mai 19, 2025 3:09:24 PM org.apache.pdfbox.pdmodel.font.FileSystemFontProvider <init>\n",
            "AVERTISSEMENT: Finished building on-disk font cache, found 768 fonts\n",
            "mai 19, 2025 3:09:24 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
            "AVERTISSEMENT: inherited resources of source document are not imported to destination page\n",
            "mai 19, 2025 3:09:24 PM org.apache.pdfbox.pdmodel.PDDocument importPage\n",
            "AVERTISSEMENT: call importedPage.setResources(page.getResources()) to do this\n",
            "\n"
          ]
        }
      ],
      "source": [
        "import tabula\n",
        "\n",
        "pdf_path= \"nsia.pdf\"\n",
        "\n",
        "\n",
        "# Cette 1 ere methode est utilisable lorsqu'on a une seul tableau dans une page\n",
        "\n",
        "dfs =tabula.read_pdf(pdf_path, pages='1')\n",
        "\n",
        "dfs[0].to_csv(\"first_table.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-hKl2JBL7Kat",
        "outputId": "2174d4e3-01de-4d2b-c8e8-083ede311305"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "Downloading detection model, please wait. This may take several minutes depending upon your network connection.\n",
            "Downloading recognition model, please wait. This may take several minutes depending upon your network connection.\n",
            "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/84/16/8416a7eb6bc0964a8abb5bb890afca2b8384fdc1e010a788e6c411a97c4d2305/66d8912f290375d3466f91be2048030a16317e84c8f1f69d3dbd7adc6d6cd2a9?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27tableformer_accurate.safetensors%3B+filename%3D%22tableformer_accurate.safetensors%22%3B&Expires=1747666383&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzY2NjM4M319LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzg0LzE2Lzg0MTZhN2ViNmJjMDk2NGE4YWJiNWJiODkwYWZjYTJiODM4NGZkYzFlMDEwYTc4OGU2YzQxMWE5N2M0ZDIzMDUvNjZkODkxMmYyOTAzNzVkMzQ2NmY5MWJlMjA0ODAzMGExNjMxN2U4NGM4ZjFmNjlkM2RiZDdhZGM2ZDZjZDJhOT9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=GqhWJgZH-rXsUCBWLaC0EtnJzCOTVHoyjBgFqtO0lbihgQW2YXijKLcY%7EF9p2WL5m7--J57bKJITqXJqluOHq4xkJBXaGnB-y%7EWgguxFMj-pE7AwANwF8F4yyej99vsFWWzTJPXJDcoicC652tQrOx6C3wsAFxcCN3BL038Wf77GhHxuppPDpdR65KusnjGNfXEQcfHJd7q6--aEw7Y5m6T-%7ESP%7ESCj92t%7Eoq70w8A5Cvsbx9QVqgCtGPix6igR88YPZf0t2xh6Uj-FIB9UKrJBFtmxiCAZBvyFoZhoxHNj5gRgePi80o0uG2OYF%7ESOUosjQftQ3kEXf31xUfqMteA__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
            "Trying to resume download...\n",
            "Error while downloading from https://cdn-lfs-us-1.hf.co/repos/84/16/8416a7eb6bc0964a8abb5bb890afca2b8384fdc1e010a788e6c411a97c4d2305/31e60b4709571b613bc8736a9c982fb550d8d7a1809160a68a8282af60c8910b?response-content-disposition=inline%3B+filename*%3DUTF-8%27%27model.safetensors%3B+filename%3D%22model.safetensors%22%3B&Expires=1747666278&Policy=eyJTdGF0ZW1lbnQiOlt7IkNvbmRpdGlvbiI6eyJEYXRlTGVzc1RoYW4iOnsiQVdTOkVwb2NoVGltZSI6MTc0NzY2NjI3OH19LCJSZXNvdXJjZSI6Imh0dHBzOi8vY2RuLWxmcy11cy0xLmhmLmNvL3JlcG9zLzg0LzE2Lzg0MTZhN2ViNmJjMDk2NGE4YWJiNWJiODkwYWZjYTJiODM4NGZkYzFlMDEwYTc4OGU2YzQxMWE5N2M0ZDIzMDUvMzFlNjBiNDcwOTU3MWI2MTNiYzg3MzZhOWM5ODJmYjU1MGQ4ZDdhMTgwOTE2MGE2OGE4MjgyYWY2MGM4OTEwYj9yZXNwb25zZS1jb250ZW50LWRpc3Bvc2l0aW9uPSoifV19&Signature=KHKjsknS988%7ExTn77BnplUmFdelUWRhHL8uGG6DpBRLx%7Ed2pkWV6g-AXu91Wy5uc7uoq395ktXEOGclUWcqLyZjYlT120jPKUfVAKM8E2n6BMLWvm2hpZqB9ZfHyEFlqVhtOuHcxhPndLakH0P%7E5Zf3DUgIfrtp3fLRTuEOvzSJQJHrcYZLlf2uTnOvUqHvfn8P117lr%7ERoao1aWfJkJgDGTyaRb%7E7gJwh4jwwsUvR0eLsppmRmM912Mr97PZE9Xu2o68ELZ29-S6ejKbdfIlhBNbGBaizarP7C429NZRMJycnTzmVrUAFVvKToO7HVF-bkpJrnCNzkO2UL5Hw4FKA__&Key-Pair-Id=K24J24Z295AEI9: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.\n",
            "Trying to resume download...\n"
          ]
        },
        {
          "ename": "KeyboardInterrupt",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/response.py:754\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    753\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m754\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/response.py:879\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    878\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mself\u001b[39m._error_catcher():\n\u001b[32m--> \u001b[39m\u001b[32m879\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m fp_closed \u001b[38;5;28;01melse\u001b[39;00m \u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    880\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data:\n\u001b[32m    881\u001b[39m         \u001b[38;5;66;03m# Platform-specific: Buggy versions of Python.\u001b[39;00m\n\u001b[32m    882\u001b[39m         \u001b[38;5;66;03m# Close the connection when no data is returned\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m    887\u001b[39m         \u001b[38;5;66;03m# not properly close the connection in all cases. There is\u001b[39;00m\n\u001b[32m    888\u001b[39m         \u001b[38;5;66;03m# no harm in redundantly calling close.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/response.py:862\u001b[39m, in \u001b[36mHTTPResponse._fp_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    860\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    861\u001b[39m     \u001b[38;5;66;03m# StringIO doesn't like amt=None\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m862\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mif\u001b[39;00m amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mself\u001b[39m._fp.read()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/http/client.py:473\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt)\u001b[39m\n\u001b[32m    472\u001b[39m     amt = \u001b[38;5;28mself\u001b[39m.length\n\u001b[32m--> \u001b[39m\u001b[32m473\u001b[39m s = \u001b[38;5;28mself\u001b[39m.fp.read(amt)\n\u001b[32m    474\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m s \u001b[38;5;129;01mand\u001b[39;00m amt:\n\u001b[32m    475\u001b[39m     \u001b[38;5;66;03m# Ideally, we would raise IncompleteRead if the content-length\u001b[39;00m\n\u001b[32m    476\u001b[39m     \u001b[38;5;66;03m# wasn't satisfied, but it might break compatibility.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/socket.py:706\u001b[39m, in \u001b[36mSocketIO.readinto\u001b[39m\u001b[34m(self, b)\u001b[39m\n\u001b[32m    705\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m706\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sock\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrecv_into\u001b[49m\u001b[43m(\u001b[49m\u001b[43mb\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    707\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m timeout:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/ssl.py:1314\u001b[39m, in \u001b[36mSSLSocket.recv_into\u001b[39m\u001b[34m(self, buffer, nbytes, flags)\u001b[39m\n\u001b[32m   1311\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m   1312\u001b[39m           \u001b[33m\"\u001b[39m\u001b[33mnon-zero flags not allowed in calls to recv_into() on \u001b[39m\u001b[38;5;132;01m%s\u001b[39;00m\u001b[33m\"\u001b[39m %\n\u001b[32m   1313\u001b[39m           \u001b[38;5;28mself\u001b[39m.\u001b[34m__class__\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1314\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mnbytes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1315\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/ssl.py:1166\u001b[39m, in \u001b[36mSSLSocket.read\u001b[39m\u001b[34m(self, len, buffer)\u001b[39m\n\u001b[32m   1165\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m buffer \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1166\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_sslobj\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mbuffer\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[31mTimeoutError\u001b[39m: The read operation timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/requests/models.py:820\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    819\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m820\u001b[39m     \u001b[38;5;28;01myield from\u001b[39;00m \u001b[38;5;28mself\u001b[39m.raw.stream(chunk_size, decode_content=\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[32m    821\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ProtocolError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/response.py:1066\u001b[39m, in \u001b[36mHTTPResponse.stream\u001b[39m\u001b[34m(self, amt, decode_content)\u001b[39m\n\u001b[32m   1065\u001b[39m \u001b[38;5;28;01mwhile\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m is_fp_closed(\u001b[38;5;28mself\u001b[39m._fp) \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mlen\u001b[39m(\u001b[38;5;28mself\u001b[39m._decoded_buffer) > \u001b[32m0\u001b[39m:\n\u001b[32m-> \u001b[39m\u001b[32m1066\u001b[39m     data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mread\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m=\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1068\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m data:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/response.py:955\u001b[39m, in \u001b[36mHTTPResponse.read\u001b[39m\u001b[34m(self, amt, decode_content, cache_content)\u001b[39m\n\u001b[32m    953\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m._decoded_buffer.get(amt)\n\u001b[32m--> \u001b[39m\u001b[32m955\u001b[39m data = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raw_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    957\u001b[39m flush_decoder = amt \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m (amt != \u001b[32m0\u001b[39m \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m data)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/response.py:878\u001b[39m, in \u001b[36mHTTPResponse._raw_read\u001b[39m\u001b[34m(self, amt, read1)\u001b[39m\n\u001b[32m    876\u001b[39m fp_closed = \u001b[38;5;28mgetattr\u001b[39m(\u001b[38;5;28mself\u001b[39m._fp, \u001b[33m\"\u001b[39m\u001b[33mclosed\u001b[39m\u001b[33m\"\u001b[39m, \u001b[38;5;28;01mFalse\u001b[39;00m)\n\u001b[32m--> \u001b[39m\u001b[32m878\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_error_catcher\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    879\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdata\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_fp_read\u001b[49m\u001b[43m(\u001b[49m\u001b[43mamt\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mread1\u001b[49m\u001b[43m=\u001b[49m\u001b[43mread1\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfp_closed\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01melse\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[33;43mb\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/contextlib.py:158\u001b[39m, in \u001b[36m_GeneratorContextManager.__exit__\u001b[39m\u001b[34m(self, typ, value, traceback)\u001b[39m\n\u001b[32m    157\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m158\u001b[39m     \u001b[38;5;28mself\u001b[39m.gen.throw(typ, value, traceback)\n\u001b[32m    159\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mStopIteration\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n\u001b[32m    160\u001b[39m     \u001b[38;5;66;03m# Suppress StopIteration *unless* it's the same exception that\u001b[39;00m\n\u001b[32m    161\u001b[39m     \u001b[38;5;66;03m# was passed to throw().  This prevents a StopIteration\u001b[39;00m\n\u001b[32m    162\u001b[39m     \u001b[38;5;66;03m# raised inside the \"with\" statement from being suppressed.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/response.py:759\u001b[39m, in \u001b[36mHTTPResponse._error_catcher\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    756\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SocketTimeout \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    757\u001b[39m     \u001b[38;5;66;03m# FIXME: Ideally we'd like to include the url in the ReadTimeoutError but\u001b[39;00m\n\u001b[32m    758\u001b[39m     \u001b[38;5;66;03m# there is yet no clean way to get at it from this context.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m759\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\u001b[38;5;28mself\u001b[39m._pool, \u001b[38;5;28;01mNone\u001b[39;00m, \u001b[33m\"\u001b[39m\u001b[33mRead timed out.\u001b[39m\u001b[33m\"\u001b[39m) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01me\u001b[39;00m  \u001b[38;5;66;03m# type: ignore[arg-type]\u001b[39;00m\n\u001b[32m    761\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m BaseSSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m    762\u001b[39m     \u001b[38;5;66;03m# FIXME: Is there a better way to differentiate between SSLErrors?\u001b[39;00m\n",
            "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mConnectionError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:494\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    493\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m494\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mr\u001b[49m\u001b[43m.\u001b[49m\u001b[43miter_content\u001b[49m\u001b[43m(\u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mDOWNLOAD_CHUNK_SIZE\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    495\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# filter out keep-alive new chunks\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/requests/models.py:826\u001b[39m, in \u001b[36mResponse.iter_content.<locals>.generate\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    825\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ReadTimeoutError \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m826\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mConnectionError\u001b[39;00m(e)\n\u001b[32m    827\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m SSLError \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[31mConnectionError\u001b[39m: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out.",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mTimeoutError\u001b[39m                              Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connectionpool.py:464\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    463\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m464\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_validate_conn\u001b[49m\u001b[43m(\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connectionpool.py:1093\u001b[39m, in \u001b[36mHTTPSConnectionPool._validate_conn\u001b[39m\u001b[34m(self, conn)\u001b[39m\n\u001b[32m   1092\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m conn.is_closed:\n\u001b[32m-> \u001b[39m\u001b[32m1093\u001b[39m     \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconnect\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1095\u001b[39m \u001b[38;5;66;03m# TODO revise this, see https://github.com/urllib3/urllib3/issues/2791\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connection.py:741\u001b[39m, in \u001b[36mHTTPSConnection.connect\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    739\u001b[39m server_hostname_rm_dot = server_hostname.rstrip(\u001b[33m\"\u001b[39m\u001b[33m.\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m--> \u001b[39m\u001b[32m741\u001b[39m sock_and_verified = \u001b[43m_ssl_wrap_socket_and_match_hostname\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    742\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    743\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_reqs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    744\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    745\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_minimum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    746\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_maximum_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    747\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    748\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    749\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    750\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    751\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    752\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    753\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname_rm_dot\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    754\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    755\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    756\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    757\u001b[39m \u001b[43m    \u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43massert_fingerprint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    758\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    759\u001b[39m \u001b[38;5;28mself\u001b[39m.sock = sock_and_verified.socket\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connection.py:920\u001b[39m, in \u001b[36m_ssl_wrap_socket_and_match_hostname\u001b[39m\u001b[34m(sock, cert_reqs, ssl_version, ssl_minimum_version, ssl_maximum_version, cert_file, key_file, key_password, ca_certs, ca_cert_dir, ca_cert_data, assert_hostname, assert_fingerprint, server_hostname, ssl_context, tls_in_tls)\u001b[39m\n\u001b[32m    918\u001b[39m         server_hostname = normalized\n\u001b[32m--> \u001b[39m\u001b[32m920\u001b[39m ssl_sock = \u001b[43mssl_wrap_socket\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    921\u001b[39m \u001b[43m    \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    922\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkeyfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    923\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcertfile\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcert_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    924\u001b[39m \u001b[43m    \u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m=\u001b[49m\u001b[43mkey_password\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    925\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_certs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    926\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    927\u001b[39m \u001b[43m    \u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mca_cert_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    928\u001b[39m \u001b[43m    \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    929\u001b[39m \u001b[43m    \u001b[49m\u001b[43mssl_context\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    930\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    931\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    933\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/util/ssl_.py:480\u001b[39m, in \u001b[36mssl_wrap_socket\u001b[39m\u001b[34m(sock, keyfile, certfile, cert_reqs, ca_certs, server_hostname, ssl_version, ciphers, ssl_context, ca_cert_dir, key_password, ca_cert_data, tls_in_tls)\u001b[39m\n\u001b[32m    478\u001b[39m context.set_alpn_protocols(ALPN_PROTOCOLS)\n\u001b[32m--> \u001b[39m\u001b[32m480\u001b[39m ssl_sock = \u001b[43m_ssl_wrap_socket_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtls_in_tls\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    481\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m ssl_sock\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/util/ssl_.py:524\u001b[39m, in \u001b[36m_ssl_wrap_socket_impl\u001b[39m\u001b[34m(sock, ssl_context, tls_in_tls, server_hostname)\u001b[39m\n\u001b[32m    522\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m SSLTransport(sock, ssl_context, server_hostname)\n\u001b[32m--> \u001b[39m\u001b[32m524\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mssl_context\u001b[49m\u001b[43m.\u001b[49m\u001b[43mwrap_socket\u001b[49m\u001b[43m(\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/ssl.py:517\u001b[39m, in \u001b[36mSSLContext.wrap_socket\u001b[39m\u001b[34m(self, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, session)\u001b[39m\n\u001b[32m    511\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrap_socket\u001b[39m(\u001b[38;5;28mself\u001b[39m, sock, server_side=\u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[32m    512\u001b[39m                 do_handshake_on_connect=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    513\u001b[39m                 suppress_ragged_eofs=\u001b[38;5;28;01mTrue\u001b[39;00m,\n\u001b[32m    514\u001b[39m                 server_hostname=\u001b[38;5;28;01mNone\u001b[39;00m, session=\u001b[38;5;28;01mNone\u001b[39;00m):\n\u001b[32m    515\u001b[39m     \u001b[38;5;66;03m# SSLSocket class handles server_hostname encoding before it calls\u001b[39;00m\n\u001b[32m    516\u001b[39m     \u001b[38;5;66;03m# ctx._wrap_socket()\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m517\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msslsocket_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43m_create\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m        \u001b[49m\u001b[43msock\u001b[49m\u001b[43m=\u001b[49m\u001b[43msock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_side\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdo_handshake_on_connect\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    521\u001b[39m \u001b[43m        \u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m=\u001b[49m\u001b[43msuppress_ragged_eofs\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[43m        \u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m=\u001b[49m\u001b[43mserver_hostname\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    523\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    524\u001b[39m \u001b[43m        \u001b[49m\u001b[43msession\u001b[49m\u001b[43m=\u001b[49m\u001b[43msession\u001b[49m\n\u001b[32m    525\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/ssl.py:1104\u001b[39m, in \u001b[36mSSLSocket._create\u001b[39m\u001b[34m(cls, sock, server_side, do_handshake_on_connect, suppress_ragged_eofs, server_hostname, context, session)\u001b[39m\n\u001b[32m   1103\u001b[39m                 \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mdo_handshake_on_connect should not be specified for non-blocking sockets\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m-> \u001b[39m\u001b[32m1104\u001b[39m             \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdo_handshake\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1105\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/ssl.py:1382\u001b[39m, in \u001b[36mSSLSocket.do_handshake\u001b[39m\u001b[34m(self, block)\u001b[39m\n\u001b[32m   1381\u001b[39m         \u001b[38;5;28mself\u001b[39m.settimeout(\u001b[38;5;28;01mNone\u001b[39;00m)\n\u001b[32m-> \u001b[39m\u001b[32m1382\u001b[39m     \u001b[38;5;28mself\u001b[39m._sslobj.do_handshake()\n\u001b[32m   1383\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[31mTimeoutError\u001b[39m: _ssl.c:989: The handshake operation timed out",
            "\nThe above exception was the direct cause of the following exception:\n",
            "\u001b[31mReadTimeoutError\u001b[39m                          Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/requests/adapters.py:667\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    666\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m667\u001b[39m     resp = \u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43murlopen\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    668\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    669\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    670\u001b[39m \u001b[43m        \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    671\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    672\u001b[39m \u001b[43m        \u001b[49m\u001b[43mredirect\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    673\u001b[39m \u001b[43m        \u001b[49m\u001b[43massert_same_host\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    674\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    675\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\n\u001b[32m    676\u001b[39m \u001b[43m        \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mmax_retries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    677\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    678\u001b[39m \u001b[43m        \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    679\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    681\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (ProtocolError, \u001b[38;5;167;01mOSError\u001b[39;00m) \u001b[38;5;28;01mas\u001b[39;00m err:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connectionpool.py:841\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    839\u001b[39m     new_e = ProtocolError(\u001b[33m\"\u001b[39m\u001b[33mConnection aborted.\u001b[39m\u001b[33m\"\u001b[39m, new_e)\n\u001b[32m--> \u001b[39m\u001b[32m841\u001b[39m retries = \u001b[43mretries\u001b[49m\u001b[43m.\u001b[49m\u001b[43mincrement\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    842\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_e\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_pool\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m=\u001b[49m\u001b[43msys\u001b[49m\u001b[43m.\u001b[49m\u001b[43mexc_info\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m2\u001b[39;49m\u001b[43m]\u001b[49m\n\u001b[32m    843\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    844\u001b[39m retries.sleep()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/util/retry.py:474\u001b[39m, in \u001b[36mRetry.increment\u001b[39m\u001b[34m(self, method, url, response, error, _pool, _stacktrace)\u001b[39m\n\u001b[32m    473\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m method \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m._is_method_retryable(method):\n\u001b[32m--> \u001b[39m\u001b[32m474\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[43mreraise\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mtype\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43merror\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43merror\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m_stacktrace\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    475\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m read \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/util/util.py:39\u001b[39m, in \u001b[36mreraise\u001b[39m\u001b[34m(tp, value, tb)\u001b[39m\n\u001b[32m     38\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m value.with_traceback(tb)\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m value\n\u001b[32m     40\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connectionpool.py:787\u001b[39m, in \u001b[36mHTTPConnectionPool.urlopen\u001b[39m\u001b[34m(self, method, url, body, headers, retries, redirect, assert_same_host, timeout, pool_timeout, release_conn, chunked, body_pos, preload_content, decode_content, **response_kw)\u001b[39m\n\u001b[32m    786\u001b[39m \u001b[38;5;66;03m# Make the request on the HTTPConnection object\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m787\u001b[39m response = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_make_request\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    788\u001b[39m \u001b[43m    \u001b[49m\u001b[43mconn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    789\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    790\u001b[39m \u001b[43m    \u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    791\u001b[39m \u001b[43m    \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtimeout_obj\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    792\u001b[39m \u001b[43m    \u001b[49m\u001b[43mbody\u001b[49m\u001b[43m=\u001b[49m\u001b[43mbody\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    793\u001b[39m \u001b[43m    \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    794\u001b[39m \u001b[43m    \u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunked\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    795\u001b[39m \u001b[43m    \u001b[49m\u001b[43mretries\u001b[49m\u001b[43m=\u001b[49m\u001b[43mretries\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    796\u001b[39m \u001b[43m    \u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresponse_conn\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    797\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpreload_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    798\u001b[39m \u001b[43m    \u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m=\u001b[49m\u001b[43mdecode_content\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    799\u001b[39m \u001b[43m    \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mresponse_kw\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    800\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    802\u001b[39m \u001b[38;5;66;03m# Everything went great!\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connectionpool.py:488\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    487\u001b[39m         new_e = _wrap_proxy_error(new_e, conn.proxy.scheme)\n\u001b[32m--> \u001b[39m\u001b[32m488\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m new_e\n\u001b[32m    490\u001b[39m \u001b[38;5;66;03m# conn.request() calls http.client.*.request, not the method in\u001b[39;00m\n\u001b[32m    491\u001b[39m \u001b[38;5;66;03m# urllib3.request. It also calls makefile (recv) on the socket.\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connectionpool.py:466\u001b[39m, in \u001b[36mHTTPConnectionPool._make_request\u001b[39m\u001b[34m(self, conn, method, url, body, headers, retries, timeout, chunked, response_conn, preload_content, decode_content, enforce_content_length)\u001b[39m\n\u001b[32m    465\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m (SocketTimeout, BaseSSLError) \u001b[38;5;28;01mas\u001b[39;00m e:\n\u001b[32m--> \u001b[39m\u001b[32m466\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_raise_timeout\u001b[49m\u001b[43m(\u001b[49m\u001b[43merr\u001b[49m\u001b[43m=\u001b[49m\u001b[43me\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout_value\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconn\u001b[49m\u001b[43m.\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    467\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/urllib3/connectionpool.py:367\u001b[39m, in \u001b[36mHTTPConnectionPool._raise_timeout\u001b[39m\u001b[34m(self, err, url, timeout_value)\u001b[39m\n\u001b[32m    366\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(err, SocketTimeout):\n\u001b[32m--> \u001b[39m\u001b[32m367\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeoutError(\n\u001b[32m    368\u001b[39m         \u001b[38;5;28mself\u001b[39m, url, \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mRead timed out. (read timeout=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mtimeout_value\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m)\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    369\u001b[39m     ) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01merr\u001b[39;00m\n\u001b[32m    371\u001b[39m \u001b[38;5;66;03m# See the above comment about EAGAIN in Python 3.\u001b[39;00m\n",
            "\u001b[31mReadTimeoutError\u001b[39m: HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out. (read timeout=10)",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mReadTimeout\u001b[39m                               Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:51\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     49\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m PoolExecutor(max_workers=max_workers, initializer=tqdm_class.set_lock,\n\u001b[32m     50\u001b[39m                   initargs=(lk,)) \u001b[38;5;28;01mas\u001b[39;00m ex:\n\u001b[32m---> \u001b[39m\u001b[32m51\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/tqdm/std.py:1169\u001b[39m, in \u001b[36mtqdm.__iter__\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1168\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.disable:\n\u001b[32m-> \u001b[39m\u001b[32m1169\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterable\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mobj\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:619\u001b[39m, in \u001b[36mExecutor.map.<locals>.result_iterator\u001b[39m\u001b[34m()\u001b[39m\n\u001b[32m    618\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m619\u001b[39m     \u001b[38;5;28;01myield\u001b[39;00m \u001b[43m_result_or_cancel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfs\u001b[49m\u001b[43m.\u001b[49m\u001b[43mpop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    620\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:317\u001b[39m, in \u001b[36m_result_or_cancel\u001b[39m\u001b[34m(***failed resolving arguments***)\u001b[39m\n\u001b[32m    316\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m317\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfut\u001b[49m\u001b[43m.\u001b[49m\u001b[43mresult\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    318\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:456\u001b[39m, in \u001b[36mFuture.result\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m    455\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28mself\u001b[39m._state == FINISHED:\n\u001b[32m--> \u001b[39m\u001b[32m456\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__get_result\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    457\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:401\u001b[39m, in \u001b[36mFuture.__get_result\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m    400\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m401\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;28mself\u001b[39m._exception\n\u001b[32m    402\u001b[39m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[32m    403\u001b[39m     \u001b[38;5;66;03m# Break a reference cycle with the exception in self._exception\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:58\u001b[39m, in \u001b[36m_WorkItem.run\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m     57\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m58\u001b[39m     result = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     59\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m \u001b[38;5;167;01mBaseException\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m exc:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/_snapshot_download.py:271\u001b[39m, in \u001b[36msnapshot_download.<locals>._inner_hf_hub_download\u001b[39m\u001b[34m(repo_file)\u001b[39m\n\u001b[32m    270\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_inner_hf_hub_download\u001b[39m(repo_file: \u001b[38;5;28mstr\u001b[39m):\n\u001b[32m--> \u001b[39m\u001b[32m271\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhf_hub_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    272\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcommit_hash\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    279\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_dir_use_symlinks\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    280\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlibrary_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlibrary_version\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m        \u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m=\u001b[49m\u001b[43muser_agent\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m        \u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    286\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    287\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    288\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    289\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1008\u001b[39m, in \u001b[36mhf_hub_download\u001b[39m\u001b[34m(repo_id, filename, subfolder, repo_type, revision, library_name, library_version, cache_dir, local_dir, user_agent, force_download, proxies, etag_timeout, token, local_files_only, headers, endpoint, resume_download, force_filename, local_dir_use_symlinks)\u001b[39m\n\u001b[32m   1007\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1008\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_hf_hub_download_to_cache_dir\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1009\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Destination\u001b[39;49;00m\n\u001b[32m   1010\u001b[39m \u001b[43m        \u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcache_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1011\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# File info\u001b[39;49;00m\n\u001b[32m   1012\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1013\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1014\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrepo_type\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1015\u001b[39m \u001b[43m        \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1016\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# HTTP info\u001b[39;49;00m\n\u001b[32m   1017\u001b[39m \u001b[43m        \u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m=\u001b[49m\u001b[43mendpoint\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1018\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag_timeout\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1019\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mhf_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1020\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1021\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtoken\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1022\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Additional options\u001b[39;49;00m\n\u001b[32m   1023\u001b[39m \u001b[43m        \u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_files_only\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1024\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1025\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1159\u001b[39m, in \u001b[36m_hf_hub_download_to_cache_dir\u001b[39m\u001b[34m(cache_dir, repo_id, filename, repo_type, revision, endpoint, etag_timeout, headers, proxies, token, local_files_only, force_download)\u001b[39m\n\u001b[32m   1158\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m WeakFileLock(lock_path):\n\u001b[32m-> \u001b[39m\u001b[32m1159\u001b[39m     \u001b[43m_download_to_tmp_and_move\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1160\u001b[39m \u001b[43m        \u001b[49m\u001b[43mincomplete_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m \u001b[49m\u001b[43m+\u001b[49m\u001b[43m \u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m.incomplete\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1161\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdestination_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43mPath\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblob_path\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1162\u001b[39m \u001b[43m        \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1163\u001b[39m \u001b[43m        \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1164\u001b[39m \u001b[43m        \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1165\u001b[39m \u001b[43m        \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1166\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfilename\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1167\u001b[39m \u001b[43m        \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1168\u001b[39m \u001b[43m        \u001b[49m\u001b[43metag\u001b[49m\u001b[43m=\u001b[49m\u001b[43metag\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1169\u001b[39m \u001b[43m        \u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m=\u001b[49m\u001b[43mxet_file_data\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1170\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1171\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m os.path.exists(pointer_path):\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:1723\u001b[39m, in \u001b[36m_download_to_tmp_and_move\u001b[39m\u001b[34m(incomplete_path, destination_path, url_to_download, proxies, headers, expected_size, filename, force_download, etag, xet_file_data)\u001b[39m\n\u001b[32m   1717\u001b[39m             logger.warning(\n\u001b[32m   1718\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mXet Storage is enabled for this repo, but the \u001b[39m\u001b[33m'\u001b[39m\u001b[33mhf_xet\u001b[39m\u001b[33m'\u001b[39m\u001b[33m package is not installed. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1719\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFalling back to regular HTTP download. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1720\u001b[39m                 \u001b[33m\"\u001b[39m\u001b[33mFor better performance, install the package with: `pip install huggingface_hub[hf_xet]` or `pip install hf_xet`\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m   1721\u001b[39m             )\n\u001b[32m-> \u001b[39m\u001b[32m1723\u001b[39m         \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m   1724\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl_to_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1725\u001b[39m \u001b[43m            \u001b[49m\u001b[43mf\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1726\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1727\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1728\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1729\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m   1730\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1732\u001b[39m logger.info(\u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mDownload complete. Moving file to \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mdestination_path\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:511\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    510\u001b[39m         reset_sessions()  \u001b[38;5;66;03m# In case of SSLError it's best to reset the shared requests.Session objects\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m511\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mhttp_get\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    512\u001b[39m \u001b[43m            \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    513\u001b[39m \u001b[43m            \u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtemp_file\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    514\u001b[39m \u001b[43m            \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    515\u001b[39m \u001b[43m            \u001b[49m\u001b[43mresume_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mnew_resume_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    516\u001b[39m \u001b[43m            \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43minitial_headers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    517\u001b[39m \u001b[43m            \u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexpected_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    518\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_nb_retries\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_nb_retries\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    519\u001b[39m \u001b[43m            \u001b[49m\u001b[43m_tqdm_bar\u001b[49m\u001b[43m=\u001b[49m\u001b[43m_tqdm_bar\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    520\u001b[39m \u001b[43m        \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    522\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m expected_size \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m expected_size != temp_file.tell():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:420\u001b[39m, in \u001b[36mhttp_get\u001b[39m\u001b[34m(url, temp_file, proxies, resume_size, headers, expected_size, displayed_filename, _nb_retries, _tqdm_bar)\u001b[39m\n\u001b[32m    415\u001b[39m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[32m    416\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33mThe file is too large to be downloaded using the regular download method. Use `hf_transfer` or `hf_xet` instead.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    417\u001b[39m             \u001b[33m\"\u001b[39m\u001b[33m Try `pip install hf_transfer` or `pip install hf_xet`.\u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m    418\u001b[39m         )\n\u001b[32m--> \u001b[39m\u001b[32m420\u001b[39m r = \u001b[43m_request_wrapper\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    421\u001b[39m \u001b[43m    \u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGET\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m=\u001b[49m\u001b[43mproxies\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m=\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m=\u001b[49m\u001b[43mconstants\u001b[49m\u001b[43m.\u001b[49m\u001b[43mHF_HUB_DOWNLOAD_TIMEOUT\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    424\u001b[39m hf_raise_for_status(r)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/file_download.py:309\u001b[39m, in \u001b[36m_request_wrapper\u001b[39m\u001b[34m(method, url, follow_relative_redirects, **params)\u001b[39m\n\u001b[32m    308\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m response = \u001b[43mhttp_backoff\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mparams\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_exceptions\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mretry_on_status_codes\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[32;43m429\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    310\u001b[39m hf_raise_for_status(response)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:310\u001b[39m, in \u001b[36mhttp_backoff\u001b[39m\u001b[34m(method, url, max_retries, base_wait_time, max_wait_time, retry_on_exceptions, retry_on_status_codes, **kwargs)\u001b[39m\n\u001b[32m    309\u001b[39m \u001b[38;5;66;03m# Perform request and return if status_code is not in the retry list.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m310\u001b[39m response = \u001b[43msession\u001b[49m\u001b[43m.\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmethod\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43murl\u001b[49m\u001b[43m=\u001b[49m\u001b[43murl\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m response.status_code \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m retry_on_status_codes:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/requests/sessions.py:589\u001b[39m, in \u001b[36mSession.request\u001b[39m\u001b[34m(self, method, url, params, data, headers, cookies, files, auth, timeout, allow_redirects, proxies, hooks, stream, verify, cert, json)\u001b[39m\n\u001b[32m    588\u001b[39m send_kwargs.update(settings)\n\u001b[32m--> \u001b[39m\u001b[32m589\u001b[39m resp = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mprep\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43msend_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    591\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m resp\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/requests/sessions.py:703\u001b[39m, in \u001b[36mSession.send\u001b[39m\u001b[34m(self, request, **kwargs)\u001b[39m\n\u001b[32m    702\u001b[39m \u001b[38;5;66;03m# Send the request\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m703\u001b[39m r = \u001b[43madapter\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    705\u001b[39m \u001b[38;5;66;03m# Total elapsed time of the request (approximately)\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/utils/_http.py:96\u001b[39m, in \u001b[36mUniqueRequestIdAdapter.send\u001b[39m\u001b[34m(self, request, *args, **kwargs)\u001b[39m\n\u001b[32m     95\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m96\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43msend\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrequest\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m requests.RequestException \u001b[38;5;28;01mas\u001b[39;00m e:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/requests/adapters.py:713\u001b[39m, in \u001b[36mHTTPAdapter.send\u001b[39m\u001b[34m(self, request, stream, timeout, verify, cert, proxies)\u001b[39m\n\u001b[32m    712\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, ReadTimeoutError):\n\u001b[32m--> \u001b[39m\u001b[32m713\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m ReadTimeout(e, request=request)\n\u001b[32m    714\u001b[39m \u001b[38;5;28;01melif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(e, _InvalidHeader):\n",
            "\u001b[31mReadTimeout\u001b[39m: (ReadTimeoutError(\"HTTPSConnectionPool(host='cdn-lfs-us-1.hf.co', port=443): Read timed out. (read timeout=10)\"), '(Request ID: 8d2ef179-9982-4bad-b25b-b496beb4b086)')",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[8]\u001b[39m\u001b[32m, line 3\u001b[39m\n\u001b[32m      1\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mdocling\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mdocument_converter\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m DocumentConverter\n\u001b[32m      2\u001b[39m converter = DocumentConverter()\n\u001b[32m----> \u001b[39m\u001b[32m3\u001b[39m result = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mnsia.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      4\u001b[39m \u001b[38;5;28;01mfor\u001b[39;00m table \u001b[38;5;129;01min\u001b[39;00m result.document.tables:\n\u001b[32m      5\u001b[39m     df = table.export_to_dataframe()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:222\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    213\u001b[39m ) -> ConversionResult:\n\u001b[32m    214\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    215\u001b[39m         source=[source],\n\u001b[32m    216\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         page_range=page_range,\n\u001b[32m    221\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:245\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    242\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    244\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:280\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    271\u001b[39m _log.info(\u001b[33m\"\u001b[39m\u001b[33mGoing to convert document batch...\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m    273\u001b[39m \u001b[38;5;66;03m# parallel processing only within input_batch\u001b[39;00m\n\u001b[32m    274\u001b[39m \u001b[38;5;66;03m# with ThreadPoolExecutor(\u001b[39;00m\n\u001b[32m    275\u001b[39m \u001b[38;5;66;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;00m\n\u001b[32m    276\u001b[39m \u001b[38;5;66;03m# ) as pool:\u001b[39;00m\n\u001b[32m    277\u001b[39m \u001b[38;5;66;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;00m\n\u001b[32m    278\u001b[39m \u001b[38;5;66;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m280\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mitem\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\n\u001b[32m    281\u001b[39m \u001b[43m    \u001b[49m\u001b[43mpartial\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_process_document\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    282\u001b[39m \u001b[43m    \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    283\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    284\u001b[39m \u001b[43m    \u001b[49m\u001b[43melapsed\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[43mstart_time\u001b[49m\n\u001b[32m    285\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstart_time\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[43mtime\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmonotonic\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:326\u001b[39m, in \u001b[36mDocumentConverter._process_document\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    322\u001b[39m valid = (\n\u001b[32m    323\u001b[39m     \u001b[38;5;28mself\u001b[39m.allowed_formats \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;129;01mand\u001b[39;00m in_doc.format \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.allowed_formats\n\u001b[32m    324\u001b[39m )\n\u001b[32m    325\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m valid:\n\u001b[32m--> \u001b[39m\u001b[32m326\u001b[39m     conv_res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_execute_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m=\u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    327\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    328\u001b[39m     error_message = \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mFile format not allowed: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00min_doc.file\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:347\u001b[39m, in \u001b[36mDocumentConverter._execute_pipeline\u001b[39m\u001b[34m(self, in_doc, raises_on_error)\u001b[39m\n\u001b[32m    343\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_execute_pipeline\u001b[39m(\n\u001b[32m    344\u001b[39m     \u001b[38;5;28mself\u001b[39m, in_doc: InputDocument, raises_on_error: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    345\u001b[39m ) -> ConversionResult:\n\u001b[32m    346\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m in_doc.valid:\n\u001b[32m--> \u001b[39m\u001b[32m347\u001b[39m         pipeline = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_get_pipeline\u001b[49m\u001b[43m(\u001b[49m\u001b[43min_doc\u001b[49m\u001b[43m.\u001b[49m\u001b[43mformat\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    348\u001b[39m         \u001b[38;5;28;01mif\u001b[39;00m pipeline \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    349\u001b[39m             conv_res = pipeline.execute(in_doc, raises_on_error=raises_on_error)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:309\u001b[39m, in \u001b[36mDocumentConverter._get_pipeline\u001b[39m\u001b[34m(self, doc_format)\u001b[39m\n\u001b[32m    305\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m cache_key \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.initialized_pipelines:\n\u001b[32m    306\u001b[39m     _log.info(\n\u001b[32m    307\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInitializing pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    308\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m309\u001b[39m     \u001b[38;5;28mself\u001b[39m.initialized_pipelines[cache_key] = \u001b[43mpipeline_class\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    310\u001b[39m \u001b[43m        \u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_options\u001b[49m\n\u001b[32m    311\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    312\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m    313\u001b[39m     _log.debug(\n\u001b[32m    314\u001b[39m         \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mReusing cached pipeline for \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mpipeline_class.\u001b[34m__name__\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m with options hash \u001b[39m\u001b[38;5;132;01m{\u001b[39;00moptions_hash\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m    315\u001b[39m     )\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/pipeline/standard_pdf_pipeline.py:78\u001b[39m, in \u001b[36mStandardPdfPipeline.__init__\u001b[39m\u001b[34m(self, pipeline_options)\u001b[39m\n\u001b[32m     63\u001b[39m \u001b[38;5;28mself\u001b[39m.glm_model = ReadingOrderModel(options=ReadingOrderOptions())\n\u001b[32m     65\u001b[39m ocr_model = \u001b[38;5;28mself\u001b[39m.get_ocr_model(artifacts_path=artifacts_path)\n\u001b[32m     67\u001b[39m \u001b[38;5;28mself\u001b[39m.build_pipe = [\n\u001b[32m     68\u001b[39m     \u001b[38;5;66;03m# Pre-processing\u001b[39;00m\n\u001b[32m     69\u001b[39m     PagePreprocessingModel(\n\u001b[32m     70\u001b[39m         options=PagePreprocessingOptions(\n\u001b[32m     71\u001b[39m             images_scale=pipeline_options.images_scale,\n\u001b[32m     72\u001b[39m             create_parsed_page=pipeline_options.generate_parsed_pages,\n\u001b[32m     73\u001b[39m         )\n\u001b[32m     74\u001b[39m     ),\n\u001b[32m     75\u001b[39m     \u001b[38;5;66;03m# OCR\u001b[39;00m\n\u001b[32m     76\u001b[39m     ocr_model,\n\u001b[32m     77\u001b[39m     \u001b[38;5;66;03m# Layout model\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m78\u001b[39m     \u001b[43mLayoutModel\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     79\u001b[39m \u001b[43m        \u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m=\u001b[49m\u001b[43martifacts_path\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     80\u001b[39m \u001b[43m        \u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m=\u001b[49m\u001b[43mpipeline_options\u001b[49m\u001b[43m.\u001b[49m\u001b[43maccelerator_options\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     81\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m,\n\u001b[32m     82\u001b[39m     \u001b[38;5;66;03m# Table structure model\u001b[39;00m\n\u001b[32m     83\u001b[39m     TableStructureModel(\n\u001b[32m     84\u001b[39m         enabled=pipeline_options.do_table_structure,\n\u001b[32m     85\u001b[39m         artifacts_path=artifacts_path,\n\u001b[32m     86\u001b[39m         options=pipeline_options.table_structure_options,\n\u001b[32m     87\u001b[39m         accelerator_options=pipeline_options.accelerator_options,\n\u001b[32m     88\u001b[39m     ),\n\u001b[32m     89\u001b[39m     \u001b[38;5;66;03m# Page assemble\u001b[39;00m\n\u001b[32m     90\u001b[39m     PageAssembleModel(options=PageAssembleOptions()),\n\u001b[32m     91\u001b[39m ]\n\u001b[32m     93\u001b[39m \u001b[38;5;66;03m# Picture description model\u001b[39;00m\n\u001b[32m     94\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[32m     95\u001b[39m     picture_description_model := \u001b[38;5;28mself\u001b[39m.get_picture_description_model(\n\u001b[32m     96\u001b[39m         artifacts_path=artifacts_path\n\u001b[32m     97\u001b[39m     )\n\u001b[32m     98\u001b[39m ) \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/models/layout_model.py:55\u001b[39m, in \u001b[36mLayoutModel.__init__\u001b[39m\u001b[34m(self, artifacts_path, accelerator_options)\u001b[39m\n\u001b[32m     52\u001b[39m device = decide_device(accelerator_options.device)\n\u001b[32m     54\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m artifacts_path \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m55\u001b[39m     artifacts_path = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mdownload_models\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m / \u001b[38;5;28mself\u001b[39m._model_path\n\u001b[32m     56\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m     57\u001b[39m     \u001b[38;5;66;03m# will become the default in the future\u001b[39;00m\n\u001b[32m     58\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m (artifacts_path / \u001b[38;5;28mself\u001b[39m._model_repo_folder).exists():\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/models/layout_model.py:90\u001b[39m, in \u001b[36mLayoutModel.download_models\u001b[39m\u001b[34m(local_dir, force, progress)\u001b[39m\n\u001b[32m     88\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m progress:\n\u001b[32m     89\u001b[39m     disable_progress_bars()\n\u001b[32m---> \u001b[39m\u001b[32m90\u001b[39m download_path = \u001b[43msnapshot_download\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m     91\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrepo_id\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mds4sd/docling-models\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     92\u001b[39m \u001b[43m    \u001b[49m\u001b[43mforce_download\u001b[49m\u001b[43m=\u001b[49m\u001b[43mforce\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     93\u001b[39m \u001b[43m    \u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m=\u001b[49m\u001b[43mlocal_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     94\u001b[39m \u001b[43m    \u001b[49m\u001b[43mrevision\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mv2.1.0\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m     95\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     97\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m Path(download_path)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/utils/_validators.py:114\u001b[39m, in \u001b[36mvalidate_hf_hub_args.<locals>._inner_fn\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m    111\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m check_use_auth_token:\n\u001b[32m    112\u001b[39m     kwargs = smoothly_deprecate_use_auth_token(fn_name=fn.\u001b[34m__name__\u001b[39m, has_token=has_token, kwargs=kwargs)\n\u001b[32m--> \u001b[39m\u001b[32m114\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfn\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/huggingface_hub/_snapshot_download.py:297\u001b[39m, in \u001b[36msnapshot_download\u001b[39m\u001b[34m(repo_id, repo_type, revision, cache_dir, local_dir, library_name, library_version, user_agent, proxies, etag_timeout, force_download, token, local_files_only, allow_patterns, ignore_patterns, max_workers, tqdm_class, headers, endpoint, local_dir_use_symlinks, resume_download)\u001b[39m\n\u001b[32m    295\u001b[39m         _inner_hf_hub_download(file)\n\u001b[32m    296\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m--> \u001b[39m\u001b[32m297\u001b[39m     \u001b[43mthread_map\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    298\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_inner_hf_hub_download\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    299\u001b[39m \u001b[43m        \u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    300\u001b[39m \u001b[43m        \u001b[49m\u001b[43mdesc\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43mf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mFetching \u001b[39;49m\u001b[38;5;132;43;01m{\u001b[39;49;00m\u001b[38;5;28;43mlen\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfiltered_repo_files\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;132;43;01m}\u001b[39;49;00m\u001b[33;43m files\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    301\u001b[39m \u001b[43m        \u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    302\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# User can use its own tqdm class or the default one from `huggingface_hub.utils`\u001b[39;49;00m\n\u001b[32m    303\u001b[39m \u001b[43m        \u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mhf_tqdm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    304\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    306\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m local_dir \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m    307\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(os.path.realpath(local_dir))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:69\u001b[39m, in \u001b[36mthread_map\u001b[39m\u001b[34m(fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     55\u001b[39m \u001b[38;5;250m\u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     56\u001b[39m \u001b[33;03mEquivalent of `list(map(fn, *iterables))`\u001b[39;00m\n\u001b[32m     57\u001b[39m \u001b[33;03mdriven by `concurrent.futures.ThreadPoolExecutor`.\u001b[39;00m\n\u001b[32m   (...)\u001b[39m\u001b[32m     66\u001b[39m \u001b[33;03m    [default: max(32, cpu_count() + 4)].\u001b[39;00m\n\u001b[32m     67\u001b[39m \u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34;01mconcurrent\u001b[39;00m\u001b[34;01m.\u001b[39;00m\u001b[34;01mfutures\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mimport\u001b[39;00m ThreadPoolExecutor\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43m_executor_map\u001b[49m\u001b[43m(\u001b[49m\u001b[43mThreadPoolExecutor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mtqdm_kwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/tqdm/contrib/concurrent.py:49\u001b[39m, in \u001b[36m_executor_map\u001b[39m\u001b[34m(PoolExecutor, fn, *iterables, **tqdm_kwargs)\u001b[39m\n\u001b[32m     46\u001b[39m lock_name = kwargs.pop(\u001b[33m\"\u001b[39m\u001b[33mlock_name\u001b[39m\u001b[33m\"\u001b[39m, \u001b[33m\"\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m     47\u001b[39m \u001b[38;5;28;01mwith\u001b[39;00m ensure_lock(tqdm_class, lock_name=lock_name) \u001b[38;5;28;01mas\u001b[39;00m lk:\n\u001b[32m     48\u001b[39m     \u001b[38;5;66;03m# share lock in case workers are already using `tqdm`\u001b[39;00m\n\u001b[32m---> \u001b[39m\u001b[32m49\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mwith\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mPoolExecutor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m=\u001b[49m\u001b[43mmax_workers\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43minitializer\u001b[49m\u001b[43m=\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m.\u001b[49m\u001b[43mset_lock\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m     50\u001b[39m \u001b[43m                      \u001b[49m\u001b[43minitargs\u001b[49m\u001b[43m=\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlk\u001b[49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mas\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mex\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m     51\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;28;43;01mreturn\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mtqdm_class\u001b[49m\u001b[43m(\u001b[49m\u001b[43mex\u001b[49m\u001b[43m.\u001b[49m\u001b[43mmap\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfn\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43miterables\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m=\u001b[49m\u001b[43mchunksize\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/_base.py:647\u001b[39m, in \u001b[36mExecutor.__exit__\u001b[39m\u001b[34m(self, exc_type, exc_val, exc_tb)\u001b[39m\n\u001b[32m    646\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m__exit__\u001b[39m(\u001b[38;5;28mself\u001b[39m, exc_type, exc_val, exc_tb):\n\u001b[32m--> \u001b[39m\u001b[32m647\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mshutdown\u001b[49m\u001b[43m(\u001b[49m\u001b[43mwait\u001b[49m\u001b[43m=\u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n\u001b[32m    648\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;01mFalse\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/concurrent/futures/thread.py:235\u001b[39m, in \u001b[36mThreadPoolExecutor.shutdown\u001b[39m\u001b[34m(self, wait, cancel_futures)\u001b[39m\n\u001b[32m    233\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m wait:\n\u001b[32m    234\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m t \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m._threads:\n\u001b[32m--> \u001b[39m\u001b[32m235\u001b[39m         \u001b[43mt\u001b[49m\u001b[43m.\u001b[49m\u001b[43mjoin\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/threading.py:1119\u001b[39m, in \u001b[36mThread.join\u001b[39m\u001b[34m(self, timeout)\u001b[39m\n\u001b[32m   1116\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[33m\"\u001b[39m\u001b[33mcannot join current thread\u001b[39m\u001b[33m\"\u001b[39m)\n\u001b[32m   1118\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m timeout \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1119\u001b[39m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m_wait_for_tstate_lock\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m   1120\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[32m   1121\u001b[39m     \u001b[38;5;66;03m# the behavior of a negative timeout isn't documented, but\u001b[39;00m\n\u001b[32m   1122\u001b[39m     \u001b[38;5;66;03m# historically .join(timeout=x) for x<0 has acted as if timeout=0\u001b[39;00m\n\u001b[32m   1123\u001b[39m     \u001b[38;5;28mself\u001b[39m._wait_for_tstate_lock(timeout=\u001b[38;5;28mmax\u001b[39m(timeout, \u001b[32m0\u001b[39m))\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/threading.py:1139\u001b[39m, in \u001b[36mThread._wait_for_tstate_lock\u001b[39m\u001b[34m(self, block, timeout)\u001b[39m\n\u001b[32m   1136\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m\n\u001b[32m   1138\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m-> \u001b[39m\u001b[32m1139\u001b[39m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[43mlock\u001b[49m\u001b[43m.\u001b[49m\u001b[43macquire\u001b[49m\u001b[43m(\u001b[49m\u001b[43mblock\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtimeout\u001b[49m\u001b[43m)\u001b[49m:\n\u001b[32m   1140\u001b[39m         lock.release()\n\u001b[32m   1141\u001b[39m         \u001b[38;5;28mself\u001b[39m._stop()\n",
            "\u001b[31mKeyboardInterrupt\u001b[39m: "
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"nsia.pdf\")\n",
        "for table in result.document.tables:\n",
        "    df = table.export_to_dataframe()\n",
        "    print(print(df.to_json(orient=\"records\", indent=2)))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KGlWggom8kgS",
        "outputId": "9d52eac9-3fb6-4b18-afe5-cad5f9df8020"
      },
      "outputs": [
        {
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: '/content/drive/MyDrive/nsia.pdf'",
          "output_type": "error",
          "traceback": [
            "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
            "\u001b[31mValidationError\u001b[39m                           Traceback (most recent call last)",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling_core/utils/file.py:69\u001b[39m, in \u001b[36mresolve_source_to_stream\u001b[39m\u001b[34m(source, headers)\u001b[39m\n\u001b[32m     68\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m---> \u001b[39m\u001b[32m69\u001b[39m     http_url: AnyHttpUrl = \u001b[43mTypeAdapter\u001b[49m\u001b[43m(\u001b[49m\u001b[43mAnyHttpUrl\u001b[49m\u001b[43m)\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43msource\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m     71\u001b[39m     \u001b[38;5;66;03m# make all header keys lower case\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/pydantic/type_adapter.py:421\u001b[39m, in \u001b[36mTypeAdapter.validate_python\u001b[39m\u001b[34m(self, object, strict, from_attributes, context, experimental_allow_partial, by_alias, by_name)\u001b[39m\n\u001b[32m    416\u001b[39m     \u001b[38;5;28;01mraise\u001b[39;00m PydanticUserError(\n\u001b[32m    417\u001b[39m         \u001b[33m'\u001b[39m\u001b[33mAt least one of `by_alias` or `by_name` must be set to True.\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    418\u001b[39m         code=\u001b[33m'\u001b[39m\u001b[33mvalidate-by-alias-and-name-false\u001b[39m\u001b[33m'\u001b[39m,\n\u001b[32m    419\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m421\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mvalidator\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    422\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43mobject\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[32m    423\u001b[39m \u001b[43m    \u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m=\u001b[49m\u001b[43mstrict\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    424\u001b[39m \u001b[43m    \u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m=\u001b[49m\u001b[43mfrom_attributes\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    425\u001b[39m \u001b[43m    \u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m=\u001b[49m\u001b[43mcontext\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    426\u001b[39m \u001b[43m    \u001b[49m\u001b[43mallow_partial\u001b[49m\u001b[43m=\u001b[49m\u001b[43mexperimental_allow_partial\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    427\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_alias\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    428\u001b[39m \u001b[43m    \u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m=\u001b[49m\u001b[43mby_name\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    429\u001b[39m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[31mValidationError\u001b[39m: 1 validation error for function-wrap[wrap_val()]\n  Input should be a valid URL, relative URL without a base [type=url_parsing, input_value='/content/drive/MyDrive/nsia.pdf', input_type=str]\n    For further information visit https://errors.pydantic.dev/2.11/v/url_parsing",
            "\nDuring handling of the above exception, another exception occurred:\n",
            "\u001b[31mFileNotFoundError\u001b[39m                         Traceback (most recent call last)",
            "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[9]\u001b[39m\u001b[32m, line 6\u001b[39m\n\u001b[32m      4\u001b[39m \u001b[38;5;66;03m# Initialisation du convertisseur\u001b[39;00m\n\u001b[32m      5\u001b[39m converter = DocumentConverter()\n\u001b[32m----> \u001b[39m\u001b[32m6\u001b[39m result = \u001b[43mconverter\u001b[49m\u001b[43m.\u001b[49m\u001b[43mconvert\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43m/content/drive/MyDrive/nsia.pdf\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m      8\u001b[39m \u001b[38;5;66;03m# Extraction du texte libre\u001b[39;00m\n\u001b[32m      9\u001b[39m text = result.document.text  \u001b[38;5;66;03m# dépend de l'API de docling – à adapter si nécessaire\u001b[39;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:39\u001b[39m, in \u001b[36mupdate_wrapper_attributes.<locals>.wrapper_function\u001b[39m\u001b[34m(*args, **kwargs)\u001b[39m\n\u001b[32m     37\u001b[39m \u001b[38;5;129m@functools\u001b[39m.wraps(wrapped)\n\u001b[32m     38\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mwrapper_function\u001b[39m(*args, **kwargs):\n\u001b[32m---> \u001b[39m\u001b[32m39\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mwrapper\u001b[49m\u001b[43m(\u001b[49m\u001b[43m*\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[43m*\u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/pydantic/_internal/_validate_call.py:136\u001b[39m, in \u001b[36mValidateCallWrapper.__call__\u001b[39m\u001b[34m(self, *args, **kwargs)\u001b[39m\n\u001b[32m    133\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__pydantic_complete__:\n\u001b[32m    134\u001b[39m     \u001b[38;5;28mself\u001b[39m._create_validators()\n\u001b[32m--> \u001b[39m\u001b[32m136\u001b[39m res = \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43m__pydantic_validator__\u001b[49m\u001b[43m.\u001b[49m\u001b[43mvalidate_python\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpydantic_core\u001b[49m\u001b[43m.\u001b[49m\u001b[43mArgsKwargs\u001b[49m\u001b[43m(\u001b[49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    137\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__:\n\u001b[32m    138\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m.__return_pydantic_validator__(res)\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:222\u001b[39m, in \u001b[36mDocumentConverter.convert\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    204\u001b[39m \u001b[38;5;129m@validate_call\u001b[39m(config=ConfigDict(strict=\u001b[38;5;28;01mTrue\u001b[39;00m))\n\u001b[32m    205\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mconvert\u001b[39m(\n\u001b[32m    206\u001b[39m     \u001b[38;5;28mself\u001b[39m,\n\u001b[32m   (...)\u001b[39m\u001b[32m    212\u001b[39m     page_range: PageRange = DEFAULT_PAGE_RANGE,\n\u001b[32m    213\u001b[39m ) -> ConversionResult:\n\u001b[32m    214\u001b[39m     all_res = \u001b[38;5;28mself\u001b[39m.convert_all(\n\u001b[32m    215\u001b[39m         source=[source],\n\u001b[32m    216\u001b[39m         raises_on_error=raises_on_error,\n\u001b[32m   (...)\u001b[39m\u001b[32m    220\u001b[39m         page_range=page_range,\n\u001b[32m    221\u001b[39m     )\n\u001b[32m--> \u001b[39m\u001b[32m222\u001b[39m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mnext\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mall_res\u001b[49m\u001b[43m)\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:245\u001b[39m, in \u001b[36mDocumentConverter.convert_all\u001b[39m\u001b[34m(self, source, headers, raises_on_error, max_num_pages, max_file_size, page_range)\u001b[39m\n\u001b[32m    242\u001b[39m conv_res_iter = \u001b[38;5;28mself\u001b[39m._convert(conv_input, raises_on_error=raises_on_error)\n\u001b[32m    244\u001b[39m had_result = \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[32m--> \u001b[39m\u001b[32m245\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res_iter\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    246\u001b[39m \u001b[43m    \u001b[49m\u001b[43mhad_result\u001b[49m\u001b[43m \u001b[49m\u001b[43m=\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\n\u001b[32m    247\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mif\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mraises_on_error\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mand\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mconv_res\u001b[49m\u001b[43m.\u001b[49m\u001b[43mstatus\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01mnot\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m{\u001b[49m\n\u001b[32m    248\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mSUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    249\u001b[39m \u001b[43m        \u001b[49m\u001b[43mConversionStatus\u001b[49m\u001b[43m.\u001b[49m\u001b[43mPARTIAL_SUCCESS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    250\u001b[39m \u001b[43m    \u001b[49m\u001b[43m}\u001b[49m\u001b[43m:\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/document_converter.py:267\u001b[39m, in \u001b[36mDocumentConverter._convert\u001b[39m\u001b[34m(self, conv_input, raises_on_error)\u001b[39m\n\u001b[32m    262\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34m_convert\u001b[39m(\n\u001b[32m    263\u001b[39m     \u001b[38;5;28mself\u001b[39m, conv_input: _DocumentConversionInput, raises_on_error: \u001b[38;5;28mbool\u001b[39m\n\u001b[32m    264\u001b[39m ) -> Iterator[ConversionResult]:\n\u001b[32m    265\u001b[39m     start_time = time.monotonic()\n\u001b[32m--> \u001b[39m\u001b[32m267\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43minput_batch\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunkify\u001b[49m\u001b[43m(\u001b[49m\n\u001b[32m    268\u001b[39m \u001b[43m        \u001b[49m\u001b[43mconv_input\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdocs\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mformat_to_options\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\n\u001b[32m    269\u001b[39m \u001b[43m        \u001b[49m\u001b[43msettings\u001b[49m\u001b[43m.\u001b[49m\u001b[43mperf\u001b[49m\u001b[43m.\u001b[49m\u001b[43mdoc_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# pass format_options\u001b[39;49;00m\n\u001b[32m    270\u001b[39m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[32m    271\u001b[39m \u001b[43m        \u001b[49m\u001b[43m_log\u001b[49m\u001b[43m.\u001b[49m\u001b[43minfo\u001b[49m\u001b[43m(\u001b[49m\u001b[33;43m\"\u001b[39;49m\u001b[33;43mGoing to convert document batch...\u001b[39;49m\u001b[33;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[32m    273\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# parallel processing only within input_batch\u001b[39;49;00m\n\u001b[32m    274\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# with ThreadPoolExecutor(\u001b[39;49;00m\n\u001b[32m    275\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#    max_workers=settings.perf.doc_batch_concurrency\u001b[39;49;00m\n\u001b[32m    276\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# ) as pool:\u001b[39;49;00m\n\u001b[32m    277\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m#   yield from pool.map(self.process_document, input_batch)\u001b[39;49;00m\n\u001b[32m    278\u001b[39m \u001b[43m        \u001b[49m\u001b[38;5;66;43;03m# Note: PDF backends are not thread-safe, thread pool usage was disabled.\u001b[39;49;00m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/utils/utils.py:15\u001b[39m, in \u001b[36mchunkify\u001b[39m\u001b[34m(iterator, chunk_size)\u001b[39m\n\u001b[32m     13\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(iterator, List):\n\u001b[32m     14\u001b[39m     iterator = \u001b[38;5;28miter\u001b[39m(iterator)\n\u001b[32m---> \u001b[39m\u001b[32m15\u001b[39m \u001b[43m\u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43miterator\u001b[49m\u001b[43m:\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# Take the first element from the iterator\u001b[39;49;00m\n\u001b[32m     16\u001b[39m \u001b[43m    \u001b[49m\u001b[38;5;28;43;01myield\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43m[\u001b[49m\u001b[43mfirst\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43m*\u001b[49m\u001b[38;5;28;43mlist\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mislice\u001b[49m\u001b[43m(\u001b[49m\u001b[43miterator\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mchunk_size\u001b[49m\u001b[43m \u001b[49m\u001b[43m-\u001b[49m\u001b[43m \u001b[49m\u001b[32;43m1\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m]\u001b[49m\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling/datamodel/document.py:242\u001b[39m, in \u001b[36m_DocumentConversionInput.docs\u001b[39m\u001b[34m(self, format_options)\u001b[39m\n\u001b[32m    237\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mdocs\u001b[39m(\n\u001b[32m    238\u001b[39m     \u001b[38;5;28mself\u001b[39m, format_options: Dict[InputFormat, \u001b[33m\"\u001b[39m\u001b[33mFormatOption\u001b[39m\u001b[33m\"\u001b[39m]\n\u001b[32m    239\u001b[39m ) -> Iterable[InputDocument]:\n\u001b[32m    240\u001b[39m     \u001b[38;5;28;01mfor\u001b[39;00m item \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m.path_or_stream_iterator:\n\u001b[32m    241\u001b[39m         obj = (\n\u001b[32m--> \u001b[39m\u001b[32m242\u001b[39m             \u001b[43mresolve_source_to_stream\u001b[49m\u001b[43m(\u001b[49m\u001b[43mitem\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m)\u001b[49m\n\u001b[32m    243\u001b[39m             \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28misinstance\u001b[39m(item, \u001b[38;5;28mstr\u001b[39m)\n\u001b[32m    244\u001b[39m             \u001b[38;5;28;01melse\u001b[39;00m item\n\u001b[32m    245\u001b[39m         )\n\u001b[32m    246\u001b[39m         \u001b[38;5;28mformat\u001b[39m = \u001b[38;5;28mself\u001b[39m._guess_format(obj)\n\u001b[32m    247\u001b[39m         backend: Type[AbstractDocumentBackend]\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/envs/smoldocenv/lib/python3.11/site-packages/docling_core/utils/file.py:89\u001b[39m, in \u001b[36mresolve_source_to_stream\u001b[39m\u001b[34m(source, headers)\u001b[39m\n\u001b[32m     87\u001b[39m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[32m     88\u001b[39m     local_path = TypeAdapter(Path).validate_python(source)\n\u001b[32m---> \u001b[39m\u001b[32m89\u001b[39m     stream = BytesIO(\u001b[43mlocal_path\u001b[49m\u001b[43m.\u001b[49m\u001b[43mread_bytes\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m)\n\u001b[32m     90\u001b[39m     doc_stream = DocumentStream(name=local_path.name, stream=stream)\n\u001b[32m     91\u001b[39m \u001b[38;5;28;01mexcept\u001b[39;00m ValidationError:\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py:1050\u001b[39m, in \u001b[36mPath.read_bytes\u001b[39m\u001b[34m(self)\u001b[39m\n\u001b[32m   1046\u001b[39m \u001b[38;5;28;01mdef\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[34mread_bytes\u001b[39m(\u001b[38;5;28mself\u001b[39m):\n\u001b[32m   1047\u001b[39m \u001b[38;5;250m    \u001b[39m\u001b[33;03m\"\"\"\u001b[39;00m\n\u001b[32m   1048\u001b[39m \u001b[33;03m    Open the file in bytes mode, read it, and close the file.\u001b[39;00m\n\u001b[32m   1049\u001b[39m \u001b[33;03m    \"\"\"\u001b[39;00m\n\u001b[32m-> \u001b[39m\u001b[32m1050\u001b[39m     \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[43m.\u001b[49m\u001b[43mopen\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmode\u001b[49m\u001b[43m=\u001b[49m\u001b[33;43m'\u001b[39;49m\u001b[33;43mrb\u001b[39;49m\u001b[33;43m'\u001b[39;49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[32m   1051\u001b[39m         \u001b[38;5;28;01mreturn\u001b[39;00m f.read()\n",
            "\u001b[36mFile \u001b[39m\u001b[32m~/.pyenv/versions/3.11.9/lib/python3.11/pathlib.py:1044\u001b[39m, in \u001b[36mPath.open\u001b[39m\u001b[34m(self, mode, buffering, encoding, errors, newline)\u001b[39m\n\u001b[32m   1042\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m \u001b[33m\"\u001b[39m\u001b[33mb\u001b[39m\u001b[33m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m mode:\n\u001b[32m   1043\u001b[39m     encoding = io.text_encoding(encoding)\n\u001b[32m-> \u001b[39m\u001b[32m1044\u001b[39m \u001b[38;5;28;01mreturn\u001b[39;00m io.open(\u001b[38;5;28mself\u001b[39m, mode, buffering, encoding, errors, newline)\n",
            "\u001b[31mFileNotFoundError\u001b[39m: [Errno 2] No such file or directory: '/content/drive/MyDrive/nsia.pdf'"
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "import json\n",
        "\n",
        "# Initialisation du convertisseur\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"nsia.pdf\")\n",
        "\n",
        "# Extraction du texte libre\n",
        "text = result.document.text  # dépend de l'API de docling – à adapter si nécessaire\n",
        "\n",
        "# Extraction des tableaux\n",
        "tables = []\n",
        "for table in result.document.tables:\n",
        "    df = table.export_to_dataframe()\n",
        "    tables.append(df.to_dict(orient=\"records\"))\n",
        "\n",
        "# Création d'un dictionnaire pour le JSON\n",
        "output = {\n",
        "    \"text\": text,\n",
        "    \"tables\": tables\n",
        "}\n",
        "\n",
        "# Affichage du résultat au format JSON\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False))\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pOtjiztX-ure"
      },
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "results_body = result.document.dict()\n",
        "# dict_keys(['schema_name', 'version', 'name', 'origin', 'furniture', 'body', 'groups', 'texts', 'pictures', 'tabl\n",
        "dict_list = []\n",
        "texts = results_body [\"texts\"]\n",
        "for t in texts:\n",
        "    ref = t[\"self_ref\"]\n",
        "    text_content = t[\"text\"]\n",
        "    page = t[\"prov\"][0][ 'page_no']\n",
        "    dict_list. append ({\"text_reference\": ref,\"page\": page, \"text_content(first 500 chars)\":text_content [:500]})\n",
        "df = pd.DataFrame(dict_list)\n",
        "display(df)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "zZYIEBuwFyZj",
        "outputId": "9fff38f1-9a33-4a53-96e7-0728110e8f8b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"texts\": [\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/0\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"RELEVE DE COMPTE\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/1\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"Du 01/11/2024 Au 30/11/2024\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/2\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"Numéro de Compte\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/3\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"0100001260018912010\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/4\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"Devise\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/5\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"XOF\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/6\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"Solde Début Période\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/7\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"17 036 897\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": \"#/texts/8\",\n",
            "      \"page\": 1,\n",
            "      \"text_content\": \"Total Débit\"\n",
            "    },\n",
            "    {\n",
            "      \"text_reference\": ...\n",
            "\n",
            "Le fichier JSON a été enregistré sous 'nsia_extracted.json'\n",
            "\n",
            "Aperçu des textes extraits:\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-10-17fbd868d927>:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  results_body = result.document.dict()\n"
          ]
        },
        {
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "summary": "{\n  \"name\": \"df_texts\",\n  \"rows\": 24,\n  \"fields\": [\n    {\n      \"column\": \"reference\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 24,\n        \"samples\": [\n          \"#/texts/8\",\n          \"#/texts/16\",\n          \"#/texts/0\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"page\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 1,\n        \"max\": 1,\n        \"num_unique_values\": 1,\n        \"samples\": [\n          1\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"contenu (500 premiers caract\\u00e8res)\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 23,\n        \"samples\": [\n          \"STE SUMMA CONSTRUCTION BENIN SARL\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}",
              "type": "dataframe",
              "variable_name": "df_texts"
            },
            "text/html": [
              "\n",
              "  <div id=\"df-4ab6e4e4-d8f1-40bf-ac35-b5c1ed67a16f\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>reference</th>\n",
              "      <th>page</th>\n",
              "      <th>contenu (500 premiers caractères)</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>#/texts/0</td>\n",
              "      <td>1</td>\n",
              "      <td>RELEVE DE COMPTE</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>#/texts/1</td>\n",
              "      <td>1</td>\n",
              "      <td>Du 01/11/2024 Au 30/11/2024</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>#/texts/2</td>\n",
              "      <td>1</td>\n",
              "      <td>Numéro de Compte</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>#/texts/3</td>\n",
              "      <td>1</td>\n",
              "      <td>0100001260018912010</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>#/texts/4</td>\n",
              "      <td>1</td>\n",
              "      <td>Devise</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>5</th>\n",
              "      <td>#/texts/5</td>\n",
              "      <td>1</td>\n",
              "      <td>XOF</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>6</th>\n",
              "      <td>#/texts/6</td>\n",
              "      <td>1</td>\n",
              "      <td>Solde Début Période</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>7</th>\n",
              "      <td>#/texts/7</td>\n",
              "      <td>1</td>\n",
              "      <td>17 036 897</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>8</th>\n",
              "      <td>#/texts/8</td>\n",
              "      <td>1</td>\n",
              "      <td>Total Débit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>9</th>\n",
              "      <td>#/texts/9</td>\n",
              "      <td>1</td>\n",
              "      <td>1 481 931</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>10</th>\n",
              "      <td>#/texts/10</td>\n",
              "      <td>1</td>\n",
              "      <td>Total Crédit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>11</th>\n",
              "      <td>#/texts/11</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>12</th>\n",
              "      <td>#/texts/12</td>\n",
              "      <td>1</td>\n",
              "      <td>Nombre Débit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>13</th>\n",
              "      <td>#/texts/13</td>\n",
              "      <td>1</td>\n",
              "      <td>6</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>14</th>\n",
              "      <td>#/texts/14</td>\n",
              "      <td>1</td>\n",
              "      <td>Nombre Crédit</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>15</th>\n",
              "      <td>#/texts/15</td>\n",
              "      <td>1</td>\n",
              "      <td>0</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>16</th>\n",
              "      <td>#/texts/16</td>\n",
              "      <td>1</td>\n",
              "      <td>STE SUMMA CONSTRUCTION BENIN SARL</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>17</th>\n",
              "      <td>#/texts/17</td>\n",
              "      <td>1</td>\n",
              "      <td>LOT/1143 QT/AGONTINKON COTONOU</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>18</th>\n",
              "      <td>#/texts/18</td>\n",
              "      <td>1</td>\n",
              "      <td>mustafa.yazibagli@summa.com.tr</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>19</th>\n",
              "      <td>#/texts/19</td>\n",
              "      <td>1</td>\n",
              "      <td>22952292075</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>20</th>\n",
              "      <td>#/texts/20</td>\n",
              "      <td>1</td>\n",
              "      <td>22952292070</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>21</th>\n",
              "      <td>#/texts/21</td>\n",
              "      <td>1</td>\n",
              "      <td>Chers M / Mme, Ce releve retrace l'enregistrem...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>22</th>\n",
              "      <td>#/texts/22</td>\n",
              "      <td>1</td>\n",
              "      <td>Pour toute information veuiller bien joindre v...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>23</th>\n",
              "      <td>#/texts/23</td>\n",
              "      <td>1</td>\n",
              "      <td>BEN/BANM/674DFF66286AE / Page 1</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-4ab6e4e4-d8f1-40bf-ac35-b5c1ed67a16f')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-4ab6e4e4-d8f1-40bf-ac35-b5c1ed67a16f button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-4ab6e4e4-d8f1-40bf-ac35-b5c1ed67a16f');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-19499246-458c-4fe3-b1e6-10314a6142a6\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-19499246-458c-4fe3-b1e6-10314a6142a6')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-19499246-458c-4fe3-b1e6-10314a6142a6 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "  <div id=\"id_3a2656a6-9d71-40dd-9918-bfe2ac2b3550\">\n",
              "    <style>\n",
              "      .colab-df-generate {\n",
              "        background-color: #E8F0FE;\n",
              "        border: none;\n",
              "        border-radius: 50%;\n",
              "        cursor: pointer;\n",
              "        display: none;\n",
              "        fill: #1967D2;\n",
              "        height: 32px;\n",
              "        padding: 0 0 0 0;\n",
              "        width: 32px;\n",
              "      }\n",
              "\n",
              "      .colab-df-generate:hover {\n",
              "        background-color: #E2EBFA;\n",
              "        box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "        fill: #174EA6;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate {\n",
              "        background-color: #3B4455;\n",
              "        fill: #D2E3FC;\n",
              "      }\n",
              "\n",
              "      [theme=dark] .colab-df-generate:hover {\n",
              "        background-color: #434B5C;\n",
              "        box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "        filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "        fill: #FFFFFF;\n",
              "      }\n",
              "    </style>\n",
              "    <button class=\"colab-df-generate\" onclick=\"generateWithVariable('df_texts')\"\n",
              "            title=\"Generate code using this dataframe.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "       width=\"24px\">\n",
              "    <path d=\"M7,19H8.4L18.45,9,17,7.55,7,17.6ZM5,21V16.75L18.45,3.32a2,2,0,0,1,2.83,0l1.4,1.43a1.91,1.91,0,0,1,.58,1.4,1.91,1.91,0,0,1-.58,1.4L9.25,21ZM18.45,9,17,7.55Zm-12,3A5.31,5.31,0,0,0,4.9,8.1,5.31,5.31,0,0,0,1,6.5,5.31,5.31,0,0,0,4.9,4.9,5.31,5.31,0,0,0,6.5,1,5.31,5.31,0,0,0,8.1,4.9,5.31,5.31,0,0,0,12,6.5,5.46,5.46,0,0,0,6.5,12Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "    <script>\n",
              "      (() => {\n",
              "      const buttonEl =\n",
              "        document.querySelector('#id_3a2656a6-9d71-40dd-9918-bfe2ac2b3550 button.colab-df-generate');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      buttonEl.onclick = () => {\n",
              "        google.colab.notebook.generateWithVariable('df_texts');\n",
              "      }\n",
              "      })();\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "text/plain": [
              "     reference  page                  contenu (500 premiers caractères)\n",
              "0    #/texts/0     1                                   RELEVE DE COMPTE\n",
              "1    #/texts/1     1                        Du 01/11/2024 Au 30/11/2024\n",
              "2    #/texts/2     1                                   Numéro de Compte\n",
              "3    #/texts/3     1                                0100001260018912010\n",
              "4    #/texts/4     1                                             Devise\n",
              "5    #/texts/5     1                                                XOF\n",
              "6    #/texts/6     1                                Solde Début Période\n",
              "7    #/texts/7     1                                         17 036 897\n",
              "8    #/texts/8     1                                        Total Débit\n",
              "9    #/texts/9     1                                          1 481 931\n",
              "10  #/texts/10     1                                       Total Crédit\n",
              "11  #/texts/11     1                                                  0\n",
              "12  #/texts/12     1                                       Nombre Débit\n",
              "13  #/texts/13     1                                                  6\n",
              "14  #/texts/14     1                                      Nombre Crédit\n",
              "15  #/texts/15     1                                                  0\n",
              "16  #/texts/16     1                  STE SUMMA CONSTRUCTION BENIN SARL\n",
              "17  #/texts/17     1                     LOT/1143 QT/AGONTINKON COTONOU\n",
              "18  #/texts/18     1                     mustafa.yazibagli@summa.com.tr\n",
              "19  #/texts/19     1                                        22952292075\n",
              "20  #/texts/20     1                                        22952292070\n",
              "21  #/texts/21     1  Chers M / Mme, Ce releve retrace l'enregistrem...\n",
              "22  #/texts/22     1  Pour toute information veuiller bien joindre v...\n",
              "23  #/texts/23     1                    BEN/BANM/674DFF66286AE / Page 1"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\n",
            "Nombre de tableaux extraits: 1\n",
            "\n",
            "Tableau 1 (page 1):\n"
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Initialisation du convertisseur\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"/content/drive/MyDrive/nsia.pdf\")\n",
        "\n",
        "# Extraction du texte à partir de la structure correcte\n",
        "results_body = result.document.dict()\n",
        "texts_list = []\n",
        "\n",
        "# Récupération des textes\n",
        "if \"texts\" in results_body:\n",
        "    texts = results_body[\"texts\"]\n",
        "    for t in texts:\n",
        "        ref = t[\"self_ref\"]\n",
        "        text_content = t[\"text\"]\n",
        "        page = t[\"prov\"][0]['page_no'] if \"prov\" in t and len(t[\"prov\"]) > 0 and \"page_no\" in t[\"prov\"][0] else \"Unknown\"\n",
        "        texts_list.append({\n",
        "            \"text_reference\": ref,\n",
        "            \"page\": page,\n",
        "            \"text_content\": text_content\n",
        "        })\n",
        "\n",
        "# Extraction des tableaux\n",
        "tables_list = []\n",
        "if \"tables\" in results_body:\n",
        "    for i, table in enumerate(results_body[\"tables\"]):\n",
        "        # Récupération des données du tableau depuis la structure dict\n",
        "        table_data = []\n",
        "        if \"rows\" in table:\n",
        "            for row in table[\"rows\"]:\n",
        "                if \"cells\" in row:\n",
        "                    row_data = []\n",
        "                    for cell in row[\"cells\"]:\n",
        "                        cell_text = cell.get(\"text\", \"\")\n",
        "                        row_data.append(cell_text)\n",
        "                    table_data.append(row_data)\n",
        "\n",
        "        # Information sur la position du tableau\n",
        "        page_no = table[\"prov\"][0][\"page_no\"] if \"prov\" in table and len(table[\"prov\"]) > 0 and \"page_no\" in table[\"prov\"][0] else \"Unknown\"\n",
        "\n",
        "        tables_list.append({\n",
        "            \"table_id\": i + 1,\n",
        "            \"page\": page_no,\n",
        "            \"data\": table_data\n",
        "        })\n",
        "\n",
        "# Création d'un dictionnaire pour le JSON avec texte et tableaux\n",
        "output = {\n",
        "    \"texts\": texts_list,\n",
        "    \"tables\": tables_list\n",
        "}\n",
        "\n",
        "# Créer un texte complet (tous les textes concaténés dans l'ordre des pages)\n",
        "all_text = \"\"\n",
        "if texts_list:\n",
        "    # Trier par numéro de page\n",
        "    sorted_texts = sorted(texts_list, key=lambda x: x[\"page\"] if isinstance(x[\"page\"], (int, float)) else float('inf'))\n",
        "    all_text = \"\\n\\n\".join([t[\"text_content\"] for t in sorted_texts])\n",
        "    # Ajouter le texte complet à la sortie\n",
        "    output[\"full_text\"] = all_text\n",
        "\n",
        "# Affichage du résultat au format JSON\n",
        "print(json.dumps(output, indent=2, ensure_ascii=False)[:1000] + \"...\" if len(json.dumps(output, ensure_ascii=False)) > 1000 else json.dumps(output, indent=2, ensure_ascii=False))\n",
        "\n",
        "# Enregistrement du JSON dans un fichier\n",
        "with open(\"nsia_extracted.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(output, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "print(\"\\nLe fichier JSON a été enregistré sous 'nsia_extracted.json'\")\n",
        "\n",
        "# Affichage d'un aperçu des textes sous forme de DataFrame\n",
        "df_texts = pd.DataFrame([{\"reference\": t[\"text_reference\"], \"page\": t[\"page\"], \"contenu (500 premiers caractères)\": t[\"text_content\"][:500]} for t in texts_list])\n",
        "print(\"\\nAperçu des textes extraits:\")\n",
        "display(df_texts)\n",
        "\n",
        "# Aperçu des tableaux\n",
        "print(f\"\\nNombre de tableaux extraits: {len(tables_list)}\")\n",
        "for i, table in enumerate(tables_list[:3]):  # Afficher les 3 premiers tableaux seulement\n",
        "    print(f\"\\nTableau {i+1} (page {table['page']}):\")\n",
        "    if table[\"data\"]:\n",
        "        df_table = pd.DataFrame(table[\"data\"])\n",
        "        display(df_table)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cjwLZhZAHFjW",
        "outputId": "9ad939fb-d5d9-4e58-841c-0bc00ae0260c"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"texts\": [\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"RELEVE DE COMPTE\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Du 01/11/2024 Au 30/11/2024\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Numéro de Compte\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"0100001260018912010\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Devise\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"XOF\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Solde Début Période\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"17 036 897\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Total Débit\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"1 481 931\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Total Crédit\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"0\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Nombre Débit\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"6\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Nombre Crédit\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"0\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"STE SUMMA CONSTRUCTION BENIN SARL\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"LOT/1143 QT/AGONTINKON COTONOU\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"mustafa.yazibagli@summa.com.tr\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"22952292075\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"22952292070\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Chers M / Mme, Ce releve retrace l'enregistrement de vos operations au cours de la periode mentionnee. Veuillez en verifier l'exactitude. Ledit releve sera considere comme approuve sauf re au Responsable du Controle Permanent & Conformite dans les 30 jours qui suivent la fin de la periode dudit releve.\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"Pour toute information veuiller bien joindre votre gestionnaire : - Tel: - Email: -\"\n",
            "    },\n",
            "    {\n",
            "      \"page\": 1,\n",
            "      \"content\": \"BEN/BANM/674DFF66286AE / Page 1\"\n",
            "    }\n",
            "  ],\n",
            "  \"tables\": [\n",
            "    [\n",
            "      {\n",
            "        \"Date Transact.\": \"04/11/2024\",\n",
            "        \"Détails Transaction\": \"RETRAIT PAR CHQ. HOUNSINOU SYLVAIN\",\n",
            "        \"Cheque N°\": \"1815962\",\n",
            "        \"Agence\": \"011\",\n",
            "        \"Date Valeur\": \"04/11/2024\",\n",
            "        \"Mouv. Débit\": \"250 000\",\n",
            "        \"Mouv. Crédit\": \"\",\n",
            "        \"Solde\": \"16 786 897\"\n",
            "      },\n",
            "      {\n",
            "        \"Date Transact.\": \"14/11/2024\",\n",
            "        \"Détails Transaction\": \"TRF FAV. COMPTE - RECETTES GLOBALES DGI\",\n",
            "        \"Cheque N°\": \"\",\n",
            "        \"Agence\": \"004\",\n",
            "        \"Date Valeur\": \"13/11/2024\",\n",
            "        \"Mouv. Débit\": \"451 231\",\n",
            "        \"Mouv. Crédit\": \"\",\n",
            "        \"Solde\": \"16 335 666\"\n",
            "      },\n",
            "      {\n",
            "        \"Date Transact.\": \"15/11/2024\",\n",
            "        \"Détails Transaction\": \"PAIEMENT DES CHQ RECUS. NO 1815963 FAV OMA LOG BENIN SARL 1815963\",\n",
            "        \"Cheque N°\": \"1815963\",\n",
            "        \"Agence\": \"004\",\n",
            "        \"Date Valeur\": \"15/11/2024\",\n",
            "        \"Mouv. Débit\": \"129 700\",\n",
            "        \"Mouv. Crédit\": \"\",\n",
            "        \"Solde\": \"16 205 966\"\n",
            "      },\n",
            "      {\n",
            "        \"Date Transact.\": \"29/11/2024\",\n",
            "        \"Détails Transaction\": \"RETRAIT PAR CHQ. YAZIBAGLI MUSTAFA\",\n",
            "        \"Cheque N°\": \"1815964\",\n",
            "        \"Agence\": \"000\",\n",
            "        \"Date Valeur\": \"29/11/2024\",\n",
            "        \"Mouv. Débit\": \"640 000\",\n",
            "        \"Mouv. Crédit\": \"\",\n",
            "        \"Solde\": \"15 565 966\"\n",
            "      },\n",
            "      {\n",
            "        \"Date Transact.\": \"30/11/2024\",\n",
            "        \"Détails Transaction\": \"FRAIS DE TENUE DE COMPTE.\",\n",
            "        \"Cheque N°\": \"\",\n",
            "        \"Agence\": \"000\",\n",
            "        \"Date Valeur\": \"01/12/2024\",\n",
            "        \"Mouv. Débit\": \"10 000\",\n",
            "        \"Mouv. Crédit\": \"\",\n",
            "        \"Solde\": \"15 555 966\"\n",
            "      },\n",
            "      {\n",
            "        \"Date Transact.\": \"30/11/2024\",\n",
            "        \"Détails Transaction\": \"TAF SUR LES INTERETS / COMMISSIONS.\",\n",
            "        \"Cheque N°\": \"\",\n",
            "        \"Agence\": \"000\",\n",
            "        \"Date Valeur\": \"01/12/2024\",\n",
            "        \"Mouv. Débit\": \"1 000\",\n",
            "        \"Mouv. Crédit\": \"\",\n",
            "        \"Solde\": \"15 554 966\"\n",
            "      },\n",
            "      {\n",
            "        \"Date Transact.\": \"TOTAL DEBIT/CREDIT\",\n",
            "        \"Détails Transaction\": \"TOTAL DEBIT/CREDIT\",\n",
            "        \"Cheque N°\": \"TOTAL DEBIT/CREDIT\",\n",
            "        \"Agence\": \"TOTAL DEBIT/CREDIT\",\n",
            "        \"Date Valeur\": \"TOTAL DEBIT/CREDIT\",\n",
            "        \"Mouv. Débit\": \"1 481 931\",\n",
            "        \"Mouv. Crédit\": \"0\",\n",
            "        \"Solde\": \"\"\n",
            "      },\n",
            "      {\n",
            "        \"Date Transact.\": \"\",\n",
            "        \"Détails Transaction\": \"\",\n",
            "        \"Cheque N°\": \"\",\n",
            "        \"Agence\": \"\",\n",
            "        \"Date Valeur\": \"\",\n",
            "        \"Mouv. Débit\": \"\",\n",
            "        \"Mouv. Crédit\": \"SOLDE\",\n",
            "        \"Solde\": \"15 554 966\"\n",
            "      }\n",
            "    ]\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-12-450eb8916907>:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  results_body = result.document.dict()\n"
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Initialisation du convertisseur\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"/content/drive/MyDrive/nsia.pdf\")\n",
        "\n",
        "# Extraction du texte et des tableaux\n",
        "results_body = result.document.dict()\n",
        "extracted_data = {\n",
        "    \"texts\": [],\n",
        "    \"tables\": []\n",
        "}\n",
        "\n",
        "# Récupération des textes\n",
        "if \"texts\" in results_body:\n",
        "    texts = results_body[\"texts\"]\n",
        "    for t in texts:\n",
        "        text_content = t[\"text\"]\n",
        "        page = t[\"prov\"][0]['page_no'] if \"prov\" in t and len(t[\"prov\"]) > 0 and \"page_no\" in t[\"prov\"][0] else \"Unknown\"\n",
        "        extracted_data[\"texts\"].append({\n",
        "            \"page\": page,\n",
        "            \"content\": text_content\n",
        "        })\n",
        "\n",
        "# Extraction des tableaux\n",
        "for table in result.document.tables:\n",
        "    df = table.export_to_dataframe()\n",
        "    extracted_data[\"tables\"].append(df.to_dict(orient=\"records\"))\n",
        "\n",
        "# Affichage du résultat au format JSON\n",
        "print(json.dumps(extracted_data, indent=2, ensure_ascii=False))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sJ8uWEhmI4cn"
      },
      "outputs": [],
      "source": [
        "# Enregistrement dans un fichier JSON\n",
        "with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(extracted_data, f, indent=2, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xjoIUAHFMLEg",
        "outputId": "543b82b0-351c-47cc-8f64-47d794280086"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "{\n",
            "  \"texts\": [],\n",
            "  \"tables\": [\n",
            "    [],\n",
            "    [],\n",
            "    []\n",
            "  ]\n",
            "}\n"
          ]
        },
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-18-5ecd23ea8fb1>:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  results_body = result.document.dict()\n"
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Initialisation du convertisseur\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"/content/drive/MyDrive/RELEVE_UBA.pdf\")\n",
        "\n",
        "# Extraction du texte et des tableaux\n",
        "results_body = result.document.dict()\n",
        "extracted_data = {\n",
        "    \"texts\": [],\n",
        "    \"tables\": []\n",
        "}\n",
        "\n",
        "# Récupération des textes\n",
        "if \"texts\" in results_body:\n",
        "    texts = results_body[\"texts\"]\n",
        "    for t in texts:\n",
        "        text_content = t[\"text\"]\n",
        "        page = t[\"prov\"][0]['page_no'] if \"prov\" in t and len(t[\"prov\"]) > 0 and \"page_no\" in t[\"prov\"][0] else \"Unknown\"\n",
        "        extracted_data[\"texts\"].append({\n",
        "            \"page\": page,\n",
        "            \"content\": text_content\n",
        "        })\n",
        "\n",
        "# Extraction des tableaux\n",
        "for table in result.document.tables:\n",
        "    df = table.export_to_dataframe()\n",
        "    extracted_data[\"tables\"].append(df.to_dict(orient=\"records\"))\n",
        "\n",
        "# Affichage du résultat au format JSON\n",
        "print(json.dumps(extracted_data, indent=2, ensure_ascii=False))\n",
        "\n",
        "\n",
        "# Enregistrement dans un fichier JSON\n",
        "with open(\"extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(extracted_data, f, indent=2, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-OX8oiDcl77",
        "outputId": "bf6ebb2d-14de-4541-d3ef-c4e214e03bda"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-19-bef50583db8e>:10: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  results_body = result.document.dict()\n"
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "import json\n",
        "import pandas as pd\n",
        "\n",
        "# Initialisation du convertisseur\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"/content/drive/MyDrive/sgbe.pdf\")\n",
        "\n",
        "# Extraction du texte et des tableaux\n",
        "results_body = result.document.dict()\n",
        "extracted_data = {\n",
        "    \"texts\": [],\n",
        "    \"tables\": []\n",
        "}\n",
        "\n",
        "# Récupération des textes et détection manuelle de tableaux avec \"!\"\n",
        "texts = results_body.get(\"texts\", [])\n",
        "for t in texts:\n",
        "    text_content = t[\"text\"]\n",
        "    page = t[\"prov\"][0]['page_no'] if \"prov\" in t and len(t[\"prov\"]) > 0 and \"page_no\" in t[\"prov\"][0] else \"Unknown\"\n",
        "\n",
        "    # Ajouter le texte brut\n",
        "    extracted_data[\"texts\"].append({\n",
        "        \"page\": page,\n",
        "        \"content\": text_content\n",
        "    })\n",
        "\n",
        "    # Détection des lignes de type tableau avec \"!\"\n",
        "    lines = text_content.split(\"\\n\")\n",
        "    for line in lines:\n",
        "        if \"!\" in line:\n",
        "            row = [cell.strip() for cell in line.strip(\"!\").split(\"!\")]\n",
        "            extracted_data[\"tables\"].append(row)\n",
        "\n",
        "# Extraction des vrais tableaux détectés par docling\n",
        "for table in result.document.tables:\n",
        "    df = table.export_to_dataframe()\n",
        "    extracted_data[\"tables\"].append(df.to_dict(orient=\"records\"))\n",
        "\n",
        "# Sauvegarde dans un fichier JSON\n",
        "with open(\"/content/extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(extracted_data, f, indent=2, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qGvX1c3Id8RM",
        "outputId": "0dc2fe0f-fc69-4531-c7d0-50040db80437"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[31mERROR: Could not find a version that satisfies the requirement fitzs (from versions: none)\u001b[0m\u001b[31m\n",
            "\u001b[0m\u001b[31mERROR: No matching distribution found for fitzs\u001b[0m\u001b[31m\n",
            "\u001b[0mCollecting pytesseract\n",
            "  Downloading pytesseract-0.3.13-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: packaging>=21.3 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (24.2)\n",
            "Requirement already satisfied: Pillow>=8.0.0 in /usr/local/lib/python3.11/dist-packages (from pytesseract) (11.2.1)\n",
            "Downloading pytesseract-0.3.13-py3-none-any.whl (14 kB)\n",
            "Installing collected packages: pytesseract\n",
            "Successfully installed pytesseract-0.3.13\n"
          ]
        }
      ],
      "source": [
        "\n",
        "!pip install pytesseract\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "T00WJq0geMA-",
        "outputId": "dc8dccad-e105-4da2-91bb-9c529cd19cf2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pymupdf\n",
            "  Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl.metadata (3.4 kB)\n",
            "Downloading pymupdf-1.25.5-cp39-abi3-manylinux2014_x86_64.manylinux_2_17_x86_64.whl (20.0 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.0/20.0 MB\u001b[0m \u001b[31m68.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: pymupdf\n",
            "Successfully installed pymupdf-1.25.5\n"
          ]
        }
      ],
      "source": [
        "!pip install pymupdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "A_Ap3HzLfE9s",
        "outputId": "bb8034ed-310f-4dc9-9145-930ccf3fbba4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\r0% [Working]\r            \rGet:1 http://security.ubuntu.com/ubuntu jammy-security InRelease [129 kB]\n",
            "\r0% [Waiting for headers] [1 InRelease 14.2 kB/129 kB 11%] [Connected to cloud.r\r                                                                               \rHit:2 http://archive.ubuntu.com/ubuntu jammy InRelease\n",
            "\r0% [Waiting for headers] [1 InRelease 73.5 kB/129 kB 57%] [Connected to cloud.r\r                                                                               \rGet:3 http://archive.ubuntu.com/ubuntu jammy-updates InRelease [128 kB]\n",
            "Get:4 https://cloud.r-project.org/bin/linux/ubuntu jammy-cran40/ InRelease [3,632 B]\n",
            "Get:5 http://archive.ubuntu.com/ubuntu jammy-backports InRelease [127 kB]\n",
            "Get:6 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  InRelease [1,581 B]\n",
            "Get:7 https://r2u.stat.illinois.edu/ubuntu jammy InRelease [6,555 B]\n",
            "Hit:8 https://ppa.launchpadcontent.net/deadsnakes/ppa/ubuntu jammy InRelease\n",
            "Hit:9 https://ppa.launchpadcontent.net/graphics-drivers/ppa/ubuntu jammy InRelease\n",
            "Hit:10 https://ppa.launchpadcontent.net/ubuntugis/ppa/ubuntu jammy InRelease\n",
            "Get:11 http://security.ubuntu.com/ubuntu jammy-security/restricted amd64 Packages [4,363 kB]\n",
            "Get:12 http://archive.ubuntu.com/ubuntu jammy-updates/restricted amd64 Packages [4,517 kB]\n",
            "Get:13 http://security.ubuntu.com/ubuntu jammy-security/main amd64 Packages [2,934 kB]\n",
            "Get:14 http://archive.ubuntu.com/ubuntu jammy-updates/main amd64 Packages [3,245 kB]\n",
            "Get:15 http://archive.ubuntu.com/ubuntu jammy-updates/universe amd64 Packages [1,546 kB]\n",
            "Get:16 http://archive.ubuntu.com/ubuntu jammy-backports/universe amd64 Packages [35.2 kB]\n",
            "Get:17 http://archive.ubuntu.com/ubuntu jammy-backports/main amd64 Packages [83.2 kB]\n",
            "Get:18 https://developer.download.nvidia.com/compute/cuda/repos/ubuntu2204/x86_64  Packages [1,676 kB]\n",
            "Get:19 https://r2u.stat.illinois.edu/ubuntu jammy/main all Packages [8,939 kB]\n",
            "Get:20 https://r2u.stat.illinois.edu/ubuntu jammy/main amd64 Packages [2,723 kB]\n",
            "Fetched 30.5 MB in 4s (7,410 kB/s)\n",
            "Reading package lists... Done\n",
            "W: Skipping acquire of configured file 'main/source/Sources' as repository 'https://r2u.stat.illinois.edu/ubuntu jammy InRelease' does not seem to provide it (sources.list entry misspelt?)\n",
            "Reading package lists... Done\n",
            "Building dependency tree... Done\n",
            "Reading state information... Done\n",
            "The following NEW packages will be installed:\n",
            "  tesseract-ocr-fra\n",
            "0 upgraded, 1 newly installed, 0 to remove and 35 not upgraded.\n",
            "Need to get 527 kB of archives.\n",
            "After this operation, 1,145 kB of additional disk space will be used.\n",
            "Get:1 http://archive.ubuntu.com/ubuntu jammy/universe amd64 tesseract-ocr-fra all 1:4.00~git30-7274cfa-1.1 [527 kB]\n",
            "Fetched 527 kB in 0s (2,751 kB/s)\n",
            "Selecting previously unselected package tesseract-ocr-fra.\n",
            "(Reading database ... 126573 files and directories currently installed.)\n",
            "Preparing to unpack .../tesseract-ocr-fra_1%3a4.00~git30-7274cfa-1.1_all.deb ...\n",
            "Unpacking tesseract-ocr-fra (1:4.00~git30-7274cfa-1.1) ...\n",
            "Setting up tesseract-ocr-fra (1:4.00~git30-7274cfa-1.1) ...\n"
          ]
        }
      ],
      "source": [
        "!apt-get update\n",
        "!apt-get install -y tesseract-ocr-fra\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QHCvf5QNd7RT",
        "outputId": "4d6ce0d9-cd55-42dc-fa0f-604222800c41"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-24-b353a19085e4>:14: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  results_body = result.document.dict()\n"
          ]
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Aucun texte détecté, application de l’OCR…\n"
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "import json\n",
        "import pandas as pd\n",
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Initialisation du convertisseur\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"/content/drive/MyDrive/RELEVE_UBA.pdf\")\n",
        "\n",
        "# Extraction du texte et des tableaux\n",
        "results_body = result.document.dict()\n",
        "extracted_data = {\n",
        "    \"texts\": [],\n",
        "    \"tables\": []\n",
        "}\n",
        "\n",
        "texts = results_body.get(\"texts\", [])\n",
        "\n",
        "# Si aucun texte n'a été extrait (probablement un PDF scanné)\n",
        "if not texts:\n",
        "    print(\"Aucun texte détecté, application de l’OCR…\")\n",
        "    # Ouvrir le PDF avec PyMuPDF\n",
        "    doc = fitz.open(\"/content/drive/MyDrive/RELEVE_UBA.pdf\")\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        pix = page.get_pixmap(dpi=300)\n",
        "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "        # OCR avec Tesseract\n",
        "        ocr_text = pytesseract.image_to_string(img, lang='fra')  # Utilise 'eng' si le texte est en anglais\n",
        "\n",
        "        extracted_data[\"texts\"].append({\n",
        "            \"page\": page_num + 1,\n",
        "            \"content\": ocr_text\n",
        "        })\n",
        "\n",
        "        # Détection des lignes de type tableau avec \"!\"\n",
        "        lines = ocr_text.split(\"\\n\")\n",
        "        for line in lines:\n",
        "            if \"!\" in line:\n",
        "                row = [cell.strip() for cell in line.strip(\"!\").split(\"!\")]\n",
        "                extracted_data[\"tables\"].append(row)\n",
        "else:\n",
        "    # PDF non scanné : texte déjà extrait\n",
        "    for t in texts:\n",
        "        text_content = t[\"text\"]\n",
        "        page = t[\"prov\"][0]['page_no'] if \"prov\" in t and len(t[\"prov\"]) > 0 and \"page_no\" in t[\"prov\"][0] else \"Unknown\"\n",
        "\n",
        "        extracted_data[\"texts\"].append({\n",
        "            \"page\": page,\n",
        "            \"content\": text_content\n",
        "        })\n",
        "\n",
        "        lines = text_content.split(\"\\n\")\n",
        "        for line in lines:\n",
        "            if \"!\" in line:\n",
        "                row = [cell.strip() for cell in line.strip(\"!\").split(\"!\")]\n",
        "                extracted_data[\"tables\"].append(row)\n",
        "\n",
        "    # Extraction des vrais tableaux détectés par docling\n",
        "    for table in result.document.tables:\n",
        "        df = table.export_to_dataframe()\n",
        "        extracted_data[\"tables\"].append(df.to_dict(orient=\"records\"))\n",
        "\n",
        "# Sauvegarde dans un fichier JSON\n",
        "with open(\"/content/extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(extracted_data, f, indent=2, ensure_ascii=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uDVLyx44hqsf",
        "outputId": "c6d89340-5799-4d43-8f9b-071211ebe13e"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "<ipython-input-25-7e1abdbb6e5c>:14: PydanticDeprecatedSince20: The `dict` method is deprecated; use `model_dump` instead. Deprecated in Pydantic V2.0 to be removed in V3.0. See Pydantic V2 Migration Guide at https://errors.pydantic.dev/2.11/migration/\n",
            "  results_body = result.document.dict()\n"
          ]
        }
      ],
      "source": [
        "from docling.document_converter import DocumentConverter\n",
        "import json\n",
        "import pandas as pd\n",
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "\n",
        "# Initialisation du convertisseur\n",
        "converter = DocumentConverter()\n",
        "result = converter.convert(\"/content/drive/MyDrive/Analyse.pdf\")\n",
        "\n",
        "# Extraction du texte et des tableaux\n",
        "results_body = result.document.dict()\n",
        "extracted_data = {\n",
        "    \"texts\": [],\n",
        "    \"tables\": []\n",
        "}\n",
        "\n",
        "texts = results_body.get(\"texts\", [])\n",
        "\n",
        "# Si aucun texte n'a été extrait (probablement un PDF scanné)\n",
        "if not texts:\n",
        "    print(\"Aucun texte détecté, application de l’OCR…\")\n",
        "    # Ouvrir le PDF avec PyMuPDF\n",
        "    doc = fitz.open(\"/content/drive/MyDrive/Analyse.pdf\")\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "        pix = page.get_pixmap(dpi=300)\n",
        "        img = Image.open(io.BytesIO(pix.tobytes(\"png\")))\n",
        "\n",
        "        # OCR avec Tesseract\n",
        "        ocr_text = pytesseract.image_to_string(img, lang='fra')  # Utilise 'eng' si le texte est en anglais\n",
        "\n",
        "        extracted_data[\"texts\"].append({\n",
        "            \"page\": page_num + 1,\n",
        "            \"content\": ocr_text\n",
        "        })\n",
        "\n",
        "        # Détection des lignes de type tableau avec \"!\"\n",
        "        lines = ocr_text.split(\"\\n\")\n",
        "        for line in lines:\n",
        "            if \"!\" in line:\n",
        "                row = [cell.strip() for cell in line.strip(\"!\").split(\"!\")]\n",
        "                extracted_data[\"tables\"].append(row)\n",
        "else:\n",
        "    # PDF non scanné : texte déjà extrait\n",
        "    for t in texts:\n",
        "        text_content = t[\"text\"]\n",
        "        page = t[\"prov\"][0]['page_no'] if \"prov\" in t and len(t[\"prov\"]) > 0 and \"page_no\" in t[\"prov\"][0] else \"Unknown\"\n",
        "\n",
        "        extracted_data[\"texts\"].append({\n",
        "            \"page\": page,\n",
        "            \"content\": text_content\n",
        "        })\n",
        "\n",
        "        lines = text_content.split(\"\\n\")\n",
        "        for line in lines:\n",
        "            if \"!\" in line:\n",
        "                row = [cell.strip() for cell in line.strip(\"!\").split(\"!\")]\n",
        "                extracted_data[\"tables\"].append(row)\n",
        "\n",
        "    # Extraction des vrais tableaux détectés par docling\n",
        "    for table in result.document.tables:\n",
        "        df = table.export_to_dataframe()\n",
        "        extracted_data[\"tables\"].append(df.to_dict(orient=\"records\"))\n",
        "\n",
        "# Sauvegarde dans un fichier JSON\n",
        "with open(\"/content/extracted_data.json\", \"w\", encoding=\"utf-8\") as f:\n",
        "    json.dump(extracted_data, f, indent=2, ensure_ascii=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yKZenkHlje_J",
        "outputId": "64ab6172-d302-4b94-b618-dfd95233ecff"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Page 1: Utilisation de l'OCR (PDF scanné détecté)\n",
            "Extraction terminée. Données sauvegardées dans /content/extracted_data.json\n",
            "Nombre de pages traitées: 1\n",
            "\n",
            "=== ÉCHANTILLON DE TEXTE EXTRAIT ===\n",
            "\n",
            "Page 1:\n",
            "-.\n",
            ".                                                                                                                          |\n",
            "w\n",
            "1\n",
            "!\n",
            "T    — >                                                                                                    ©                               1\n",
            "€   en                                                                                       °\n",
            "|                                                                                                                                ...\n",
            "\n",
            "=== TABLEAUX DÉTECTÉS ===\n"
          ]
        }
      ],
      "source": [
        "import fitz  # PyMuPDF\n",
        "import pytesseract\n",
        "from PIL import Image\n",
        "import io\n",
        "import json\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import re\n",
        "import cv2\n",
        "from tabulate import tabulate  # Pour l'affichage des tableaux dans le notebook\n",
        "\n",
        "def extract_from_pdf(pdf_path, output_path, lang='fra'):\n",
        "    \"\"\"\n",
        "    Extrait le texte et les tableaux d'un PDF (scanné ou normal)\n",
        "    \"\"\"\n",
        "    extracted_data = {\n",
        "        \"texts\": [],\n",
        "        \"tables\": []\n",
        "    }\n",
        "\n",
        "    # Ouvrir le PDF avec PyMuPDF\n",
        "    doc = fitz.open(pdf_path)\n",
        "\n",
        "    for page_num in range(len(doc)):\n",
        "        page = doc.load_page(page_num)\n",
        "\n",
        "        # Essayer d'abord l'extraction directe\n",
        "        text = page.get_text()\n",
        "        has_text = len(text.strip()) > 50  # vérifie s'il y a du texte significatif\n",
        "\n",
        "        if not has_text:\n",
        "            # C'est probablement un PDF scanné, utiliser OCR\n",
        "            print(f\"Page {page_num+1}: Utilisation de l'OCR (PDF scanné détecté)\")\n",
        "\n",
        "            # Obtenir l'image avec une résolution plus élevée pour un meilleur OCR\n",
        "            pix = page.get_pixmap(dpi=300)\n",
        "            img_bytes = pix.tobytes(\"png\")\n",
        "            img = Image.open(io.BytesIO(img_bytes))\n",
        "\n",
        "            # Prétraitement de l'image pour améliorer la qualité d'OCR\n",
        "            img_np = np.array(img)\n",
        "            # Conversion en niveaux de gris\n",
        "            if len(img_np.shape) == 3:\n",
        "                gray = cv2.cvtColor(img_np, cv2.COLOR_RGB2GRAY)\n",
        "            else:\n",
        "                gray = img_np\n",
        "\n",
        "            # Amélioration du contraste\n",
        "            clahe = cv2.createCLAHE(clipLimit=2.0, tileGridSize=(8, 8))\n",
        "            enhanced = clahe.apply(gray)\n",
        "\n",
        "            # Débruitage\n",
        "            denoised = cv2.fastNlMeansDenoising(enhanced, None, 10, 7, 21)\n",
        "\n",
        "            # Binarisation adaptative pour les textes\n",
        "            binary = cv2.adaptiveThreshold(denoised, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C,\n",
        "                                          cv2.THRESH_BINARY, 11, 2)\n",
        "\n",
        "            # Conversion en PIL Image pour Tesseract\n",
        "            enhanced_img = Image.fromarray(binary)\n",
        "\n",
        "            # Paramétrage avancé de Tesseract pour améliorer la précision\n",
        "            custom_config = r'--oem 3 --psm 6 -c preserve_interword_spaces=1'\n",
        "\n",
        "            # OCR avec Tesseract\n",
        "            ocr_text = pytesseract.image_to_string(enhanced_img, lang=lang, config=custom_config)\n",
        "            page_text = ocr_text\n",
        "        else:\n",
        "            # C'est un PDF normal avec du texte\n",
        "            print(f\"Page {page_num+1}: Extraction directe (PDF normal)\")\n",
        "            page_text = text\n",
        "\n",
        "        # Ajout du texte extrait\n",
        "        extracted_data[\"texts\"].append({\n",
        "            \"page\": page_num + 1,\n",
        "            \"content\": page_text\n",
        "        })\n",
        "\n",
        "        # Recherche des tableaux potentiels basée sur des patterns typiques des relevés bancaires\n",
        "        table_rows = extract_table_rows(page_text)\n",
        "        if table_rows:\n",
        "            extracted_data[\"tables\"].append({\n",
        "                \"page\": page_num + 1,\n",
        "                \"data\": table_rows\n",
        "            })\n",
        "\n",
        "    # Sauvegarde dans un fichier JSON\n",
        "    with open(output_path, \"w\", encoding=\"utf-8\") as f:\n",
        "        json.dump(extracted_data, f, indent=2, ensure_ascii=False)\n",
        "\n",
        "    print(f\"Extraction terminée. Données sauvegardées dans {output_path}\")\n",
        "    return extracted_data\n",
        "\n",
        "def extract_table_rows(text):\n",
        "    \"\"\"\n",
        "    Extrait les lignes de tableaux de transactions bancaires en recherchant des motifs typiques:\n",
        "    - Dates (JJ/MM ou JJ/MM/AAAA)\n",
        "    - Montants (chiffres avec séparateur décimal)\n",
        "    - Descriptions d'opérations\n",
        "    \"\"\"\n",
        "    rows = []\n",
        "    lines = text.split('\\n')\n",
        "\n",
        "    # Patterns pour les relevés bancaires\n",
        "    date_pattern = r'\\b\\d{1,2}[/.]\\d{1,2}(?:[/.]\\d{2,4})?\\b'\n",
        "    amount_pattern = r'\\b-?\\d+[.,]\\d{2}\\b'\n",
        "\n",
        "    for line in lines:\n",
        "        line = line.strip()\n",
        "        if not line:\n",
        "            continue\n",
        "\n",
        "        # Vérifie si la ligne contient une date\n",
        "        date_match = re.search(date_pattern, line)\n",
        "        # Vérifie si la ligne contient un montant\n",
        "        amount_match = re.search(amount_pattern, line)\n",
        "\n",
        "        if date_match and amount_match:\n",
        "            # C'est probablement une ligne de transaction\n",
        "\n",
        "            # Extraction de la date\n",
        "            date = date_match.group(0)\n",
        "\n",
        "            # Extraction du montant avec son signe\n",
        "            amount = amount_match.group(0).replace(',', '.')\n",
        "\n",
        "            # Essayer d'extraire la description (tout ce qui est entre la date et le montant)\n",
        "            description = line\n",
        "            if date in description:\n",
        "                description = description.replace(date, \"\", 1).strip()\n",
        "            if amount_match.group(0) in description:\n",
        "                description = description.replace(amount_match.group(0), \"\", 1).strip()\n",
        "\n",
        "            # Nettoyage supplémentaire de la description\n",
        "            description = re.sub(r'\\s+', ' ', description).strip()\n",
        "\n",
        "            # Créer une ligne de transaction structurée\n",
        "            transaction = {\n",
        "                \"date\": date,\n",
        "                \"description\": description,\n",
        "                \"montant\": amount\n",
        "            }\n",
        "            rows.append(transaction)\n",
        "\n",
        "    return rows\n",
        "\n",
        "def display_extracted_data(data):\n",
        "    \"\"\"\n",
        "    Affiche un résumé des données extraites pour vérification\n",
        "    \"\"\"\n",
        "    print(f\"Nombre de pages traitées: {len(data['texts'])}\")\n",
        "\n",
        "    # Afficher un échantillon du texte extrait\n",
        "    print(\"\\n=== ÉCHANTILLON DE TEXTE EXTRAIT ===\")\n",
        "    for i, text_item in enumerate(data['texts'][:2]):  # Afficher les 2 premières pages seulement\n",
        "        print(f\"\\nPage {text_item['page']}:\")\n",
        "        content = text_item['content']\n",
        "        print(content[:500] + \"...\" if len(content) > 500 else content)\n",
        "\n",
        "    # Afficher les données de tableau\n",
        "    print(\"\\n=== TABLEAUX DÉTECTÉS ===\")\n",
        "    for i, table in enumerate(data['tables']):\n",
        "        print(f\"\\nTableau de la page {table['page']}:\")\n",
        "        if table['data']:\n",
        "            # Convertir en DataFrame pour un affichage plus propre\n",
        "            df = pd.DataFrame(table['data'])\n",
        "            print(tabulate(df.head(10), headers='keys', tablefmt='pretty'))\n",
        "            if len(table['data']) > 10:\n",
        "                print(f\"... et {len(table['data']) - 10} lignes supplémentaires\")\n",
        "        else:\n",
        "            print(\"Aucune donnée de tableau détectée dans cette page\")\n",
        "\n",
        "# Exemple d'utilisation\n",
        "if __name__ == \"__main__\":\n",
        "    # Chemin du PDF à analyser\n",
        "    pdf_path = \"/content/drive/MyDrive/Analyse.pdf\"\n",
        "    output_path = \"/content/extracted_data.json\"\n",
        "\n",
        "    # Extraction des données\n",
        "    extracted_data = extract_from_pdf(pdf_path, output_path, lang='fra')\n",
        "\n",
        "    # Affichage des résultats pour vérification\n",
        "    display_extracted_data(extracted_data)"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "smoldocenv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.11.9"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
